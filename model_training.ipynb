{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z78x2eoaWMA4"
      },
      "source": [
        "## **Inference menghasilkan output berupa kelas kategorikal**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AQZP7utWMA5"
      },
      "source": [
        "### **Import Package Pre-Processing**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OjtgxQQWfar",
        "outputId": "5a37c257-9584-4f15-9d05-efb9bb2893c4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPEktqFxWMA5",
        "outputId": "c263851d-2e0e-4f72-aa50-02e54441e64f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import csv\n",
        "import requests\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKEzj_hkWMA6"
      },
      "source": [
        "## **Loading Dataset dari CSV**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDlRj4EdWMA6"
      },
      "source": [
        "**Memasukkan kedalam dataframe agar mudah untuk dimanipulasi dan menjadi training model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YXAXy9gEWMA6",
        "outputId": "6077d406-111e-4762-be25-2dc220a8b251"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       userName  score  \\\n",
              "0                   Bukan Robot      1   \n",
              "1                    marsha Tea      1   \n",
              "2                   Wardi Jafar      1   \n",
              "3                  Nen _tarak92      1   \n",
              "4  Alimurrosyid Budi Rohmansyah      1   \n",
              "\n",
              "                                             content  \n",
              "0  aplikasi terjelek kebanyakan nonton iklan nya ...  \n",
              "1  jangan kebanyakan iklan kasian yang ga berlang...  \n",
              "2                       Gak ada film indonesia jelek  \n",
              "3  Aplikasi nya kenapa yah setelah di update kok ...  \n",
              "4                                              burik  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f293b10-557d-4fd7-9c8f-5bf29f928f9c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>score</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bukan Robot</td>\n",
              "      <td>1</td>\n",
              "      <td>aplikasi terjelek kebanyakan nonton iklan nya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>marsha Tea</td>\n",
              "      <td>1</td>\n",
              "      <td>jangan kebanyakan iklan kasian yang ga berlang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wardi Jafar</td>\n",
              "      <td>1</td>\n",
              "      <td>Gak ada film indonesia jelek</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nen _tarak92</td>\n",
              "      <td>1</td>\n",
              "      <td>Aplikasi nya kenapa yah setelah di update kok ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alimurrosyid Budi Rohmansyah</td>\n",
              "      <td>1</td>\n",
              "      <td>burik</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f293b10-557d-4fd7-9c8f-5bf29f928f9c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f293b10-557d-4fd7-9c8f-5bf29f928f9c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f293b10-557d-4fd7-9c8f-5bf29f928f9c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9290869d-aa71-463a-a641-f1ec39d01920\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9290869d-aa71-463a-a641-f1ec39d01920')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9290869d-aa71-463a-a641-f1ec39d01920 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "app_reviews_df",
              "summary": "{\n  \"name\": \"app_reviews_df\",\n  \"rows\": 12000,\n  \"fields\": [\n    {\n      \"column\": \"userName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11885,\n        \"samples\": [\n          \"Bayu Darmawan\",\n          \"Elahbeauty storefashion\",\n          \"ozi nuskarina\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10813,\n        \"samples\": [\n          \"paket lengkap deh soalnya ada semua\",\n          \"Apa sih CC telat banget\",\n          \"Bagus tp ada vip\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Membaca dataset dari file CSV\n",
        "app_reviews_df = pd.read_csv('https://raw.githubusercontent.com/Kanaieu/analisis-sentimen-playstore-wetv/main/wetv_reviews.csv')\n",
        "\n",
        "# Menampilkan jumlah baris dan kolom dalam DataFrame\n",
        "jumlah_ulasan, jumlah_kolom = app_reviews_df.shape\n",
        "\n",
        "# Menampilkan beberapa baris pertama dari dataset\n",
        "app_reviews_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfDZQuvXWMA7",
        "outputId": "f50b11cc-97d0-4bce-e7e1-6f366b1d3d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12000 entries, 0 to 11999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   userName  12000 non-null  object\n",
            " 1   score     12000 non-null  int64 \n",
            " 2   content   12000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 281.4+ KB\n"
          ]
        }
      ],
      "source": [
        "app_reviews_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMRLn-RXWMA7"
      },
      "source": [
        "**Membersihkan dataframe dari Value NaN dan Duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fHgu-FQHWMA8"
      },
      "outputs": [],
      "source": [
        "# Membuat DataFrame baru (clean_df) dengan menghapus baris yang memiliki nilai yang hilang (NaN) dari app_reviews_df\n",
        "clean_df = app_reviews_df.dropna()\n",
        "\n",
        "# Menghapus baris duplikat dari DataFrame clean_df\n",
        "clean_df = clean_df.drop_duplicates()\n",
        "\n",
        "# Menghitung jumlah baris dan kolom dalam DataFrame clean_df setelah menghapus duplikat\n",
        "jumlah_ulasan_setelah_hapus_duplikat, jumlah_kolom_setelah_hapus_duplikat = clean_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uMMhokdWMA8",
        "outputId": "315b7cde-9c14-4e14-d877-f062eddd3a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 11997 entries, 0 to 11999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   userName  11997 non-null  object\n",
            " 1   score     11997 non-null  int64 \n",
            " 2   content   11997 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 374.9+ KB\n"
          ]
        }
      ],
      "source": [
        "clean_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjZC3E2KWMA8"
      },
      "source": [
        "**Pre-Processing: cleaningText(text), casefoldingText(text), tokenizingText(text), filteringText(text), stemmingText(text), toSentence(list_words)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2N6bTyMAWMA8"
      },
      "outputs": [],
      "source": [
        "def cleaningText(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
        "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
        "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
        "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
        "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
        "\n",
        "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
        "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
        "    return text\n",
        "\n",
        "def casefoldingText(text): # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def tokenizingText(text): # Memecah atau membagi string, teks menjadi daftar token\n",
        "    text = word_tokenize(text)\n",
        "    return text\n",
        "\n",
        "def filteringText(text): # Menghapus stopwords dalam teks\n",
        "    listStopwords = set(stopwords.words('indonesian'))\n",
        "    listStopwords1 = set(stopwords.words('english'))\n",
        "    listStopwords.update(listStopwords1)\n",
        "    listStopwords.update(['iya','yaa','gak','nya','na','sih','ku',\"di\",\"ga\",\"ya\",\"gaa\",\"loh\",\"kah\",\"woi\",\"woii\",\"woy\"])\n",
        "    filtered = []\n",
        "    for txt in text:\n",
        "        if txt not in listStopwords:\n",
        "            filtered.append(txt)\n",
        "    text = filtered\n",
        "    return text\n",
        "\n",
        "def stemmingText(text): # Mengurangi kata ke bentuk dasarnya yang menghilangkan imbuhan awalan dan akhiran atau ke akar kata\n",
        "    # Membuat objek stemmer\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "\n",
        "    # Memecah teks menjadi daftar kata\n",
        "    words = text.split()\n",
        "\n",
        "    # Menerapkan stemming pada setiap kata dalam daftar\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    # Menggabungkan kata-kata yang telah distem\n",
        "    stemmed_text = ' '.join(stemmed_words)\n",
        "\n",
        "    return stemmed_text\n",
        "\n",
        "def toSentence(list_words): # Mengubah daftar kata menjadi kalimat\n",
        "    sentence = ' '.join(word for word in list_words)\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXsa-xcXWMA9"
      },
      "source": [
        "**Penghapusan kumpulan slang words atau kata-kata informal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qxwy48UYWMA9"
      },
      "outputs": [],
      "source": [
        "slangwords = {\"@\": \"di\", \"abis\": \"habis\", \"wtb\": \"beli\", \"masi\": \"masih\", \"wts\": \"jual\", \"wtt\": \"tukar\", \"bgt\": \"banget\", \"maks\": \"maksimal\", \"plisss\": \"tolong\", \"bgttt\": \"banget\", \"indo\": \"indonesia\", \"bgtt\": \"banget\", \"ad\": \"ada\", \"rv\": \"redvelvet\", \"plis\": \"tolong\", \"pls\": \"tolong\", \"cr\": \"sumber\", \"cod\": \"bayar ditempat\", \"adlh\": \"adalah\", \"afaik\": \"as far as i know\", \"ahaha\": \"haha\", \"aj\": \"saja\", \"ajep-ajep\": \"dunia gemerlap\", \"ak\": \"saya\", \"akika\": \"aku\", \"akkoh\": \"aku\", \"akuwh\": \"aku\", \"alay\": \"norak\", \"alow\": \"halo\", \"ambilin\": \"ambilkan\", \"ancur\": \"hancur\", \"anjrit\": \"anjing\", \"anter\": \"antar\", \"ap2\": \"apa-apa\", \"apasih\": \"apa sih\", \"apes\": \"sial\", \"aps\": \"apa\", \"aq\": \"saya\", \"aquwh\": \"aku\", \"asbun\": \"asal bunyi\", \"aseekk\": \"asyik\", \"asekk\": \"asyik\", \"asem\": \"asam\", \"aspal\": \"asli tetapi palsu\", \"astul\": \"asal tulis\", \"ato\": \"atau\", \"au ah\": \"tidak mau tahu\", \"awak\": \"saya\", \"ay\": \"sayang\", \"ayank\": \"sayang\", \"b4\": \"sebelum\", \"bakalan\": \"akan\", \"bandes\": \"bantuan desa\", \"bangedh\": \"banget\", \"banpol\": \"bantuan polisi\", \"banpur\": \"bantuan tempur\", \"basbang\": \"basi\", \"bcanda\": \"bercanda\", \"bdg\": \"bandung\", \"begajulan\": \"nakal\", \"beliin\": \"belikan\", \"bencong\": \"banci\", \"bentar\": \"sebentar\", \"ber3\": \"bertiga\", \"beresin\": \"membereskan\", \"bete\": \"bosan\", \"beud\": \"banget\", \"bg\": \"abang\", \"bgmn\": \"bagaimana\", \"bgt\": \"banget\", \"bijimane\": \"bagaimana\", \"bintal\": \"bimbingan mental\", \"bkl\": \"akan\", \"bknnya\": \"bukannya\", \"blegug\": \"bodoh\", \"blh\": \"boleh\", \"bln\": \"bulan\", \"blum\": \"belum\", \"bnci\": \"benci\", \"bnran\": \"yang benar\", \"bodor\": \"lucu\", \"bokap\": \"ayah\", \"boker\": \"buang air besar\", \"bokis\": \"bohong\", \"boljug\": \"boleh juga\", \"bonek\": \"bocah nekat\", \"boyeh\": \"boleh\", \"br\": \"baru\", \"brg\": \"bareng\", \"bro\": \"saudara laki-laki\", \"bru\": \"baru\", \"bs\": \"bisa\", \"bsen\": \"bosan\", \"bt\": \"buat\", \"btw\": \"ngomong-ngomong\", \"buaya\": \"tidak setia\", \"bubbu\": \"tidur\", \"bubu\": \"tidur\", \"bumil\": \"ibu hamil\", \"burik\": \"buruk\", \"bw\": \"bawa\", \"bwt\": \"buat\", \"byk\": \"banyak\", \"byrin\": \"bayarkan\", \"cabal\": \"sabar\", \"cadas\": \"keren\", \"calo\": \"makelar\", \"can\": \"belum\", \"capcus\": \"pergi\", \"caper\": \"cari perhatian\", \"ce\": \"cewek\", \"cekal\": \"cegah tangkal\", \"cemen\": \"penakut\", \"cengengesan\": \"tertawa\", \"cepet\": \"cepat\", \"cew\": \"cewek\", \"chuyunk\": \"sayang\", \"cimeng\": \"ganja\", \"cipika cipiki\": \"cium pipi kanan cium pipi kiri\", \"ciyh\": \"sih\", \"ckepp\": \"cakep\", \"ckp\": \"cakep\", \"cmiiw\": \"correct me if i'm wrong\", \"cmpur\": \"campur\", \"cong\": \"banci\", \"conlok\": \"cinta lokasi\", \"cowwyy\": \"maaf\", \"cp\": \"siapa\", \"cpe\": \"capek\", \"cppe\": \"capek\", \"cucok\": \"cocok\", \"cuex\": \"cuek\", \"cumi\": \"Cuma miscall\", \"cups\": \"culun\", \"curanmor\": \"pencurian kendaraan bermotor\", \"curcol\": \"curahan hati colongan\", \"cwek\": \"cewek\", \"cyin\": \"cinta\", \"d\": \"di\", \"dah\": \"deh\", \"dapet\": \"dapat\", \"de\": \"adik\", \"dek\": \"adik\", \"demen\": \"suka\", \"deyh\": \"deh\", \"dgn\": \"dengan\", \"diancurin\": \"dihancurkan\", \"dimaafin\": \"dimaafkan\", \"dimintak\": \"diminta\", \"disono\": \"di sana\", \"dket\": \"dekat\", \"dkk\": \"dan kawan-kawan\", \"dll\": \"dan lain-lain\", \"dlu\": \"dulu\", \"dngn\": \"dengan\", \"dodol\": \"bodoh\", \"doku\": \"uang\", \"dongs\": \"dong\", \"dpt\": \"dapat\", \"dri\": \"dari\", \"drmn\": \"darimana\", \"drtd\": \"dari tadi\", \"dst\": \"dan seterusnya\", \"dtg\": \"datang\", \"duh\": \"aduh\", \"duren\": \"durian\", \"ed\": \"edisi\", \"egp\": \"emang gue pikirin\", \"eke\": \"aku\", \"elu\": \"kamu\", \"emangnya\": \"memangnya\", \"emng\": \"memang\", \"endak\": \"tidak\", \"enggak\": \"tidak\", \"envy\": \"iri\", \"ex\": \"mantan\", \"fax\": \"facsimile\", \"fifo\": \"first in first out\", \"folbek\": \"follow back\", \"fyi\": \"sebagai informasi\", \"gaada\": \"tidak ada uang\", \"gag\": \"tidak\", \"gaje\": \"tidak jelas\", \"gak papa\": \"tidak apa-apa\", \"gan\": \"juragan\", \"gaptek\": \"gagap teknologi\", \"gatek\": \"gagap teknologi\", \"gawe\": \"kerja\", \"gbs\": \"tidak bisa\", \"gebetan\": \"orang yang disuka\", \"geje\": \"tidak jelas\", \"gepeng\": \"gelandangan dan pengemis\", \"ghiy\": \"lagi\", \"gile\": \"gila\", \"gimana\": \"bagaimana\", \"gino\": \"gigi nongol\", \"githu\": \"gitu\", \"gj\": \"tidak jelas\", \"gmana\": \"bagaimana\", \"gn\": \"begini\", \"goblok\": \"bodoh\", \"golput\": \"golongan putih\", \"gowes\": \"mengayuh sepeda\", \"gpny\": \"tidak punya\", \"gr\": \"gede rasa\", \"gretongan\": \"gratisan\", \"gtau\": \"tidak tahu\", \"gua\": \"saya\", \"guoblok\": \"goblok\", \"gw\": \"saya\", \"ha\": \"tertawa\", \"haha\": \"tertawa\", \"hallow\": \"halo\", \"hankam\": \"pertahanan dan keamanan\", \"hehe\": \"he\", \"helo\": \"halo\", \"hey\": \"hai\", \"hlm\": \"halaman\", \"hny\": \"hanya\", \"hoax\": \"isu bohong\", \"hr\": \"hari\", \"hrus\": \"harus\", \"hubdar\": \"perhubungan darat\", \"huff\": \"mengeluh\", \"hum\": \"rumah\", \"humz\": \"rumah\", \"ilang\": \"hilang\", \"ilfil\": \"tidak suka\", \"imho\": \"in my humble opinion\", \"imoetz\": \"imut\", \"item\": \"hitam\", \"itungan\": \"hitungan\", \"iye\": \"iya\", \"ja\": \"saja\", \"jadiin\": \"jadi\", \"jaim\": \"jaga image\", \"jayus\": \"tidak lucu\", \"jdi\": \"jadi\", \"jem\": \"jam\", \"jga\": \"juga\", \"jgnkan\": \"jangankan\", \"jir\": \"anjing\", \"jln\": \"jalan\", \"jomblo\": \"tidak punya pacar\", \"jubir\": \"juru bicara\", \"jutek\": \"galak\", \"k\": \"ke\", \"kab\": \"kabupaten\", \"kabor\": \"kabur\", \"kacrut\": \"kacau\", \"kadiv\": \"kepala divisi\", \"kagak\": \"tidak\", \"kalo\": \"kalau\", \"kampret\": \"sialan\", \"kamtibmas\": \"keamanan dan ketertiban masyarakat\", \"kamuwh\": \"kamu\", \"kanwil\": \"kantor wilayah\", \"karna\": \"karena\", \"kasubbag\": \"kepala subbagian\", \"katrok\": \"kampungan\", \"kayanya\": \"kayaknya\", \"kbr\": \"kabar\", \"kdu\": \"harus\", \"kec\": \"kecamatan\", \"kejurnas\": \"kejuaraan nasional\", \"kekeuh\": \"keras kepala\", \"kel\": \"kelurahan\", \"kemaren\": \"kemarin\", \"kepengen\": \"mau\", \"kepingin\": \"mau\", \"kepsek\": \"kepala sekolah\", \"kesbang\": \"kesatuan bangsa\", \"kesra\": \"kesejahteraan rakyat\", \"ketrima\": \"diterima\", \"kgiatan\": \"kegiatan\", \"kibul\": \"bohong\", \"kimpoi\": \"kawin\", \"kl\": \"kalau\", \"klianz\": \"kalian\", \"kloter\": \"kelompok terbang\", \"klw\": \"kalau\", \"km\": \"kamu\", \"kmps\": \"kampus\", \"kmrn\": \"kemarin\", \"knal\": \"kenal\", \"knp\": \"kenapa\", \"kodya\": \"kota madya\", \"komdis\": \"komisi disiplin\", \"komsov\": \"komunis sovyet\", \"kongkow\": \"kumpul bareng teman-teman\", \"kopdar\": \"kopi darat\", \"korup\": \"korupsi\", \"kpn\": \"kapan\", \"krenz\": \"keren\", \"krm\": \"kirim\", \"kt\": \"kita\", \"ktmu\": \"ketemu\", \"ktr\": \"kantor\", \"kuper\": \"kurang pergaulan\", \"kw\": \"imitasi\", \"kyk\": \"seperti\", \"la\": \"lah\", \"lam\": \"salam\", \"lamp\": \"lampiran\", \"lanud\": \"landasan udara\", \"latgab\": \"latihan gabungan\", \"lebay\": \"berlebihan\", \"leh\": \"boleh\", \"lelet\": \"lambat\", \"lemot\": \"lambat\", \"lgi\": \"lagi\", \"lgsg\": \"langsung\", \"liat\": \"lihat\", \"litbang\": \"penelitian dan pengembangan\", \"lmyn\": \"lumayan\", \"lo\": \"kamu\", \"loe\": \"kamu\", \"lola\": \"lambat berfikir\", \"louph\": \"cinta\", \"low\": \"kalau\", \"lp\": \"lupa\", \"luber\": \"langsung, umum, bebas, dan rahasia\", \"luchuw\": \"lucu\", \"lum\": \"belum\", \"luthu\": \"lucu\", \"lwn\": \"lawan\", \"maacih\": \"terima kasih\", \"mabal\": \"bolos\", \"macem\": \"macam\", \"macih\": \"masih\", \"maem\": \"makan\", \"magabut\": \"makan gaji buta\", \"maho\": \"homo\", \"mak jang\": \"kaget\", \"maksain\": \"memaksa\", \"malem\": \"malam\", \"mam\": \"makan\", \"maneh\": \"kamu\", \"maniez\": \"manis\", \"mao\": \"mau\", \"masukin\": \"masukkan\", \"melu\": \"ikut\", \"mepet\": \"dekat sekali\", \"mgu\": \"minggu\", \"migas\": \"minyak dan gas bumi\", \"mikol\": \"minuman beralkohol\", \"miras\": \"minuman keras\", \"mlah\": \"malah\", \"mngkn\": \"mungkin\", \"mo\": \"mau\", \"mokad\": \"mati\", \"moso\": \"masa\", \"mpe\": \"sampai\", \"msk\": \"masuk\", \"mslh\": \"masalah\", \"mt\": \"makan teman\", \"mubes\": \"musyawarah besar\", \"mulu\": \"melulu\", \"mumpung\": \"selagi\", \"munas\": \"musyawarah nasional\", \"muntaber\": \"muntah dan berak\", \"musti\": \"mesti\", \"muupz\": \"maaf\", \"mw\": \"now watching\", \"n\": \"dan\", \"nanam\": \"menanam\", \"nanya\": \"bertanya\", \"napa\": \"kenapa\", \"napi\": \"narapidana\", \"napza\": \"narkotika, alkohol, psikotropika, dan zat adiktif \", \"narkoba\": \"narkotika, psikotropika, dan obat terlarang\", \"nasgor\": \"nasi goreng\", \"nda\": \"tidak\", \"ndiri\": \"sendiri\", \"ne\": \"ini\", \"nekolin\": \"neokolonialisme\", \"nembak\": \"menyatakan cinta\", \"ngabuburit\": \"menunggu berbuka puasa\", \"ngaku\": \"mengaku\", \"ngambil\": \"mengambil\", \"nganggur\": \"tidak punya pekerjaan\", \"ngapah\": \"kenapa\", \"ngaret\": \"terlambat\", \"ngasih\": \"memberikan\", \"ngebandel\": \"berbuat bandel\", \"ngegosip\": \"bergosip\", \"ngeklaim\": \"mengklaim\", \"ngeksis\": \"menjadi eksis\", \"ngeles\": \"berkilah\", \"ngelidur\": \"menggigau\", \"ngerampok\": \"merampok\", \"ngga\": \"tidak\", \"ngibul\": \"berbohong\", \"ngiler\": \"mau\", \"ngiri\": \"iri\", \"ngisiin\": \"mengisikan\", \"ngmng\": \"bicara\", \"ngomong\": \"bicara\", \"ngubek2\": \"mencari-cari\", \"ngurus\": \"mengurus\", \"nie\": \"ini\", \"nih\": \"ini\", \"niyh\": \"nih\", \"nmr\": \"nomor\", \"nntn\": \"nonton\", \"nobar\": \"nonton bareng\", \"np\": \"now playing\", \"ntar\": \"nanti\", \"ntn\": \"nonton\", \"numpuk\": \"bertumpuk\", \"nutupin\": \"menutupi\", \"nyari\": \"mencari\", \"nyekar\": \"menyekar\", \"nyicil\": \"mencicil\", \"nyoblos\": \"mencoblos\", \"nyokap\": \"ibu\", \"ogah\": \"tidak mau\", \"ol\": \"online\", \"ongkir\": \"ongkos kirim\", \"oot\": \"out of topic\", \"org2\": \"orang-orang\", \"ortu\": \"orang tua\", \"otda\": \"otonomi daerah\", \"otw\": \"on the way, sedang di jalan\", \"pacal\": \"pacar\", \"pake\": \"pakai\", \"pala\": \"kepala\", \"pansus\": \"panitia khusus\", \"parpol\": \"partai politik\", \"pasutri\": \"pasangan suami istri\", \"pd\": \"pada\", \"pede\": \"percaya diri\", \"pelatnas\": \"pemusatan latihan nasional\", \"pemda\": \"pemerintah daerah\", \"pemkot\": \"pemerintah kota\", \"pemred\": \"pemimpin redaksi\", \"penjas\": \"pendidikan jasmani\", \"perda\": \"peraturan daerah\", \"perhatiin\": \"perhatikan\", \"pesenan\": \"pesanan\", \"pgang\": \"pegang\", \"pi\": \"tapi\", \"pilkada\": \"pemilihan kepala daerah\", \"pisan\": \"sangat\", \"pk\": \"penjahat kelamin\", \"plg\": \"paling\", \"pmrnth\": \"pemerintah\", \"polantas\": \"polisi lalu lintas\", \"ponpes\": \"pondok pesantren\", \"pp\": \"pulang pergi\", \"prg\": \"pergi\", \"prnh\": \"pernah\", \"psen\": \"pesan\", \"pst\": \"pasti\", \"pswt\": \"pesawat\", \"pw\": \"posisi nyaman\", \"qmu\": \"kamu\", \"rakor\": \"rapat koordinasi\", \"ranmor\": \"kendaraan bermotor\", \"re\": \"reply\", \"ref\": \"referensi\", \"rehab\": \"rehabilitasi\", \"rempong\": \"sulit\", \"repp\": \"balas\", \"restik\": \"reserse narkotika\", \"rhs\": \"rahasia\", \"rmh\": \"rumah\", \"ru\": \"baru\", \"ruko\": \"rumah toko\", \"rusunawa\": \"rumah susun sewa\", \"ruz\": \"terus\", \"saia\": \"saya\", \"salting\": \"salah tingkah\", \"sampe\": \"sampai\", \"samsek\": \"sama sekali\", \"sapose\": \"siapa\", \"satpam\": \"satuan pengamanan\", \"sbb\": \"sebagai berikut\", \"sbh\": \"sebuah\", \"sbnrny\": \"sebenarnya\", \"scr\": \"secara\", \"sdgkn\": \"sedangkan\", \"sdkt\": \"sedikit\", \"se7\": \"setuju\", \"sebelas dua belas\": \"mirip\", \"sembako\": \"sembilan bahan pokok\", \"sempet\": \"sempat\", \"sendratari\": \"seni drama tari\", \"sgt\": \"sangat\", \"shg\": \"sehingga\", \"siech\": \"sih\", \"sikon\": \"situasi dan kondisi\", \"sinetron\": \"sinema elektronik\", \"siramin\": \"siramkan\", \"sj\": \"saja\", \"skalian\": \"sekalian\", \"sklh\": \"sekolah\", \"skt\": \"sakit\", \"slesai\": \"selesai\", \"sll\": \"selalu\", \"slma\": \"selama\", \"slsai\": \"selesai\", \"smpt\": \"sempat\", \"smw\": \"semua\", \"sndiri\": \"sendiri\", \"soljum\": \"sholat jumat\", \"songong\": \"sombong\", \"sory\": \"maaf\", \"sosek\": \"sosial-ekonomi\", \"sotoy\": \"sok tahu\", \"spa\": \"siapa\", \"sppa\": \"siapa\", \"spt\": \"seperti\", \"srtfkt\": \"sertifikat\", \"stiap\": \"setiap\", \"stlh\": \"setelah\", \"suk\": \"masuk\", \"sumpek\": \"sempit\", \"syg\": \"sayang\", \"t4\": \"tempat\", \"tajir\": \"kaya\", \"tau\": \"tahu\", \"taw\": \"tahu\", \"td\": \"tadi\", \"tdk\": \"tidak\", \"teh\": \"kakak perempuan\", \"telat\": \"terlambat\", \"telmi\": \"telat berpikir\", \"temen\": \"teman\", \"tengil\": \"menyebalkan\", \"tepar\": \"terkapar\", \"tggu\": \"tunggu\", \"tgu\": \"tunggu\", \"thankz\": \"terima kasih\", \"thn\": \"tahun\", \"tilang\": \"bukti pelanggaran\", \"tipiwan\": \"TvOne\", \"tks\": \"terima kasih\", \"tlp\": \"telepon\", \"tls\": \"tulis\", \"tmbah\": \"tambah\", \"tmen2\": \"teman-teman\", \"tmpah\": \"tumpah\", \"tmpt\": \"tempat\", \"tngu\": \"tunggu\", \"tnyta\": \"ternyata\", \"tokai\": \"tai\", \"toserba\": \"toko serba ada\", \"tpi\": \"tapi\", \"trdhulu\": \"terdahulu\", \"trima\": \"terima kasih\", \"trm\": \"terima\", \"trs\": \"terus\", \"trutama\": \"terutama\", \"ts\": \"penulis\", \"tst\": \"tahu sama tahu\", \"ttg\": \"tentang\", \"tuch\": \"tuh\", \"tuir\": \"tua\", \"tw\": \"tahu\", \"u\": \"kamu\", \"ud\": \"sudah\", \"udah\": \"sudah\", \"ujg\": \"ujung\", \"ul\": \"ulangan\", \"unyu\": \"lucu\", \"uplot\": \"unggah\", \"urang\": \"saya\", \"usah\": \"perlu\", \"utk\": \"untuk\", \"valas\": \"valuta asing\", \"w/\": \"dengan\", \"wadir\": \"wakil direktur\", \"wamil\": \"wajib militer\", \"warkop\": \"warung kopi\", \"warteg\": \"warung tegal\", \"wat\": \"buat\", \"wkt\": \"waktu\", \"wtf\": \"what the fuck\", \"xixixi\": \"tertawa\", \"ya\": \"iya\", \"yap\": \"iya\", \"yaudah\": \"ya sudah\", \"yawdah\": \"ya sudah\", \"yg\": \"yang\", \"yl\": \"yang lain\", \"yo\": \"iya\", \"yowes\": \"ya sudah\", \"yup\": \"iya\", \"7an\": \"tujuan\", \"ababil\": \"abg labil\", \"acc\": \"accord\", \"adlah\": \"adalah\", \"adoh\": \"aduh\", \"aha\": \"tertawa\", \"aing\": \"saya\", \"aja\": \"saja\", \"ajj\": \"saja\", \"aka\": \"dikenal juga sebagai\", \"akko\": \"aku\", \"akku\": \"aku\", \"akyu\": \"aku\", \"aljasa\": \"asal jadi saja\", \"ama\": \"sama\", \"ambl\": \"ambil\", \"anjir\": \"anjing\", \"ank\": \"anak\", \"ap\": \"apa\", \"apaan\": \"apa\", \"ape\": \"apa\", \"aplot\": \"unggah\", \"apva\": \"apa\", \"aqu\": \"aku\", \"asap\": \"sesegera mungkin\", \"aseek\": \"asyik\", \"asek\": \"asyik\", \"aseknya\": \"asyiknya\", \"asoy\": \"asyik\", \"astrojim\": \"astagfirullahaladzim\", \"ath\": \"kalau begitu\", \"atuh\": \"kalau begitu\", \"ava\": \"avatar\", \"aws\": \"awas\", \"ayang\": \"sayang\", \"ayok\": \"ayo\", \"bacot\": \"banyak bicara\", \"bales\": \"balas\", \"bangdes\": \"pembangunan desa\", \"bangkotan\": \"tua\", \"banpres\": \"bantuan presiden\", \"bansarkas\": \"bantuan sarana kesehatan\", \"bazis\": \"badan amal, zakat, infak, dan sedekah\", \"bcoz\": \"karena\", \"beb\": \"sayang\", \"bejibun\": \"banyak\", \"belom\": \"belum\", \"bener\": \"benar\", \"ber2\": \"berdua\", \"berdikari\": \"berdiri di atas kaki sendiri\", \"bet\": \"banget\", \"beti\": \"beda tipis\", \"beut\": \"banget\", \"bgd\": \"banget\", \"bgs\": \"bagus\", \"bhubu\": \"tidur\", \"bimbuluh\": \"bimbingan dan penyuluhan\", \"bisi\": \"kalau-kalau\", \"bkn\": \"bukan\", \"bl\": \"beli\", \"blg\": \"bilang\", \"blm\": \"belum\", \"bls\": \"balas\", \"bnchi\": \"benci\", \"bngung\": \"bingung\", \"bnyk\": \"banyak\", \"bohay\": \"badan aduhai\", \"bokep\": \"porno\", \"bokin\": \"pacar\", \"bole\": \"boleh\", \"bolot\": \"bodoh\", \"bonyok\": \"ayah ibu\", \"bpk\": \"bapak\", \"brb\": \"segera kembali\", \"brngkt\": \"berangkat\", \"brp\": \"berapa\", \"brur\": \"saudara laki-laki\", \"bsa\": \"bisa\", \"bsk\": \"besok\", \"bu_bu\": \"tidur\", \"bubarin\": \"bubarkan\", \"buber\": \"buka bersama\", \"bujubune\": \"luar biasa\", \"buser\": \"buru sergap\", \"bwhn\": \"bawahan\", \"byar\": \"bayar\", \"byr\": \"bayar\", \"c8\": \"chat\", \"cabut\": \"pergi\", \"caem\": \"cakep\", \"cama-cama\": \"sama-sama\", \"cangcut\": \"celana dalam\", \"cape\": \"capek\", \"caur\": \"jelek\", \"cekak\": \"tidak ada uang\", \"cekidot\": \"coba lihat\", \"cemplungin\": \"cemplungkan\", \"ceper\": \"pendek\", \"ceu\": \"kakak perempuan\", \"cewe\": \"cewek\", \"cibuk\": \"sibuk\", \"cin\": \"cinta\", \"ciye\": \"cie\", \"ckck\": \"ck\", \"clbk\": \"cinta lama bersemi kembali\", \"cmpr\": \"campur\", \"cnenk\": \"senang\", \"congor\": \"mulut\", \"cow\": \"cowok\", \"coz\": \"karena\", \"cpa\": \"siapa\", \"gokil\": \"gila\", \"gombal\": \"suka merayu\", \"gpl\": \"tidak pakai lama\", \"gpp\": \"tidak apa-apa\", \"gretong\": \"gratis\", \"gt\": \"begitu\", \"gtw\": \"tidak tahu\", \"gue\": \"saya\", \"guys\": \"teman-teman\", \"gws\": \"cepat sembuh\", \"haghaghag\": \"tertawa\", \"hakhak\": \"tertawa\", \"handak\": \"bahan peledak\", \"hansip\": \"pertahanan sipil\", \"hellow\": \"halo\", \"helow\": \"halo\", \"hi\": \"hai\", \"hlng\": \"hilang\", \"hnya\": \"hanya\", \"houm\": \"rumah\", \"hrs\": \"harus\", \"hubad\": \"hubungan angkatan darat\", \"hubla\": \"perhubungan laut\", \"huft\": \"mengeluh\", \"humas\": \"hubungan masyarakat\", \"idk\": \"saya tidak tahu\", \"ilfeel\": \"tidak suka\", \"imba\": \"jago sekali\", \"imoet\": \"imut\", \"info\": \"informasi\", \"itung\": \"hitung\", \"isengin\": \"bercanda\", \"iyala\": \"iya lah\", \"iyo\": \"iya\", \"jablay\": \"jarang dibelai\", \"jadul\": \"jaman dulu\", \"jancuk\": \"anjing\", \"jd\": \"jadi\", \"jdikan\": \"jadikan\", \"jg\": \"juga\", \"jgn\": \"jangan\", \"jijay\": \"jijik\", \"jkt\": \"jakarta\", \"jnj\": \"janji\", \"jth\": \"jatuh\", \"jurdil\": \"jujur adil\", \"jwb\": \"jawab\", \"ka\": \"kakak\", \"kabag\": \"kepala bagian\", \"kacian\": \"kasihan\", \"kadit\": \"kepala direktorat\", \"kaga\": \"tidak\", \"kaka\": \"kakak\", \"kamtib\": \"keamanan dan ketertiban\", \"kamuh\": \"kamu\", \"kamyu\": \"kamu\", \"kapt\": \"kapten\", \"kasat\": \"kepala satuan\", \"kasubbid\": \"kepala subbidang\", \"kau\": \"kamu\", \"kbar\": \"kabar\", \"kcian\": \"kasihan\", \"keburu\": \"terlanjur\", \"kedubes\": \"kedutaan besar\", \"kek\": \"seperti\", \"keknya\": \"kayaknya\", \"keliatan\": \"kelihatan\", \"keneh\": \"masih\", \"kepikiran\": \"terpikirkan\", \"kepo\": \"mau tahu urusan orang\", \"kere\": \"tidak punya uang\", \"kesian\": \"kasihan\", \"ketauan\": \"ketahuan\", \"keukeuh\": \"keras kepala\", \"khan\": \"kan\", \"kibus\": \"kaki busuk\", \"kk\": \"kakak\", \"klian\": \"kalian\", \"klo\": \"kalau\", \"kluarga\": \"keluarga\", \"klwrga\": \"keluarga\", \"kmari\": \"kemari\", \"kmpus\": \"kampus\", \"kn\": \"kan\", \"knl\": \"kenal\", \"knpa\": \"kenapa\", \"kog\": \"kok\", \"kompi\": \"komputer\", \"komtiong\": \"komunis Tiongkok\", \"konjen\": \"konsulat jenderal\", \"koq\": \"kok\", \"kpd\": \"kepada\", \"kptsan\": \"keputusan\", \"krik\": \"garing\", \"krn\": \"karena\", \"ktauan\": \"ketahuan\", \"ktny\": \"katanya\", \"kudu\": \"harus\", \"kuq\": \"kok\", \"ky\": \"seperti\", \"kykny\": \"kayanya\", \"laka\": \"kecelakaan\", \"lambreta\": \"lambat\", \"lansia\": \"lanjut usia\", \"lapas\": \"lembaga pemasyarakatan\", \"lbur\": \"libur\", \"lekong\": \"laki-laki\", \"lg\": \"lagi\", \"lgkp\": \"lengkap\", \"lht\": \"lihat\", \"linmas\": \"perlindungan masyarakat\", \"lmyan\": \"lumayan\", \"lngkp\": \"lengkap\", \"loch\": \"loh\", \"lol\": \"tertawa\", \"lom\": \"belum\", \"loupz\": \"cinta\", \"lowh\": \"kamu\", \"lu\": \"kamu\", \"luchu\": \"lucu\", \"luff\": \"cinta\", \"luph\": \"cinta\", \"lw\": \"kamu\", \"lwt\": \"lewat\", \"maaciw\": \"terima kasih\", \"mabes\": \"markas besar\", \"macem-macem\": \"macam-macam\", \"madesu\": \"masa depan suram\", \"maen\": \"main\", \"mahatma\": \"maju sehat bersama\", \"mak\": \"ibu\", \"makasih\": \"terima kasih\", \"malah\": \"bahkan\", \"malu2in\": \"memalukan\", \"mamz\": \"makan\", \"manies\": \"manis\", \"mantep\": \"mantap\", \"markus\": \"makelar kasus\", \"mba\": \"mbak\", \"mending\": \"lebih baik\", \"mgkn\": \"mungkin\", \"mhn\": \"mohon\", \"miker\": \"minuman keras\", \"milis\": \"mailing list\", \"mksd\": \"maksud\", \"mls\": \"malas\", \"mnt\": \"minta\", \"moge\": \"motor gede\", \"mokat\": \"mati\", \"mosok\": \"masa\", \"msh\": \"masih\", \"mskpn\": \"meskipun\", \"msng2\": \"masing-masing\", \"muahal\": \"mahal\", \"muker\": \"musyawarah kerja\", \"mumet\": \"pusing\", \"muna\": \"munafik\", \"munaslub\": \"musyawarah nasional luar biasa\", \"musda\": \"musyawarah daerah\", \"muup\": \"maaf\", \"muuv\": \"maaf\", \"nal\": \"kenal\", \"nangis\": \"menangis\", \"naon\": \"apa\", \"napol\": \"narapidana politik\", \"naq\": \"anak\", \"narsis\": \"bangga pada diri sendiri\", \"nax\": \"anak\", \"ndak\": \"tidak\", \"ndut\": \"gendut\", \"nekolim\": \"neokolonialisme\", \"nelfon\": \"menelepon\", \"ngabis2in\": \"menghabiskan\", \"ngakak\": \"tertawa\", \"ngambek\": \"marah\", \"ngampus\": \"pergi ke kampus\", \"ngantri\": \"mengantri\", \"ngapain\": \"sedang apa\", \"ngaruh\": \"berpengaruh\", \"ngawur\": \"berbicara sembarangan\", \"ngeceng\": \"kumpul bareng-bareng\", \"ngeh\": \"sadar\", \"ngekos\": \"tinggal di kos\", \"ngelamar\": \"melamar\", \"ngeliat\": \"melihat\", \"ngemeng\": \"bicara terus-terusan\", \"ngerti\": \"mengerti\", \"nggak\": \"tidak\", \"ngikut\": \"ikut\", \"nginep\": \"menginap\", \"ngisi\": \"mengisi\", \"ngmg\": \"bicara\", \"ngocol\": \"lucu\", \"ngomongin\": \"membicarakan\", \"ngumpul\": \"berkumpul\", \"ni\": \"ini\", \"nyasar\": \"tersesat\", \"nyariin\": \"mencari\", \"nyiapin\": \"mempersiapkan\", \"nyiram\": \"menyiram\", \"nyok\": \"ayo\", \"o/\": \"oleh\", \"ok\": \"ok\", \"priksa\": \"periksa\", \"pro\": \"profesional\", \"psn\": \"pesan\", \"psti\": \"pasti\", \"puanas\": \"panas\", \"qmo\": \"kamu\", \"qt\": \"kita\", \"rame\": \"ramai\", \"raskin\": \"rakyat miskin\", \"red\": \"redaksi\", \"reg\": \"register\", \"rejeki\": \"rezeki\", \"renstra\": \"rencana strategis\", \"reskrim\": \"reserse kriminal\", \"sni\": \"sini\", \"somse\": \"sombong sekali\", \"sorry\": \"maaf\", \"sosbud\": \"sosial-budaya\", \"sospol\": \"sosial-politik\", \"sowry\": \"maaf\", \"spd\": \"sepeda\", \"sprti\": \"seperti\", \"spy\": \"supaya\", \"stelah\": \"setelah\", \"subbag\": \"subbagian\", \"sumbangin\": \"sumbangkan\", \"sy\": \"saya\", \"syp\": \"siapa\", \"tabanas\": \"tabungan pembangunan nasional\", \"tar\": \"nanti\", \"taun\": \"tahun\", \"tawh\": \"tahu\", \"tdi\": \"tadi\", \"te2p\": \"tetap\", \"tekor\": \"rugi\", \"telkom\": \"telekomunikasi\", \"telp\": \"telepon\", \"temen2\": \"teman-teman\", \"tengok\": \"menjenguk\", \"terbitin\": \"terbitkan\", \"tgl\": \"tanggal\", \"thanks\": \"terima kasih\", \"thd\": \"terhadap\", \"thx\": \"terima kasih\", \"tipi\": \"TV\", \"tkg\": \"tukang\", \"tll\": \"terlalu\", \"tlpn\": \"telepon\", \"tman\": \"teman\", \"tmbh\": \"tambah\", \"tmn2\": \"teman-teman\", \"tmph\": \"tumpah\", \"tnda\": \"tanda\", \"tnh\": \"tanah\", \"togel\": \"toto gelap\", \"tp\": \"tapi\", \"tq\": \"terima kasih\", \"trgntg\": \"tergantung\", \"trims\": \"terima kasih\", \"cb\": \"coba\", \"y\": \"ya\", \"munfik\": \"munafik\", \"reklamuk\": \"reklamasi\", \"sma\": \"sama\", \"tren\": \"trend\", \"ngehe\": \"kesal\", \"mz\": \"mas\", \"analisise\": \"analisis\", \"sadaar\": \"sadar\", \"sept\": \"september\", \"nmenarik\": \"menarik\", \"zonk\": \"bodoh\", \"rights\": \"benar\", \"simiskin\": \"miskin\", \"ngumpet\": \"sembunyi\", \"hardcore\": \"keras\", \"akhirx\": \"akhirnya\", \"solve\": \"solusi\", \"watuk\": \"batuk\", \"ngebully\": \"intimidasi\", \"masy\": \"masyarakat\", \"still\": \"masih\", \"tauk\": \"tahu\", \"mbual\": \"bual\", \"tioghoa\": \"tionghoa\", \"ngentotin\": \"senggama\", \"kentot\": \"senggama\", \"faktakta\": \"fakta\", \"sohib\": \"teman\", \"rubahnn\": \"rubah\", \"trlalu\": \"terlalu\", \"nyela\": \"cela\", \"heters\": \"pembenci\", \"nyembah\": \"sembah\", \"most\": \"paling\", \"ikon\": \"lambang\", \"light\": \"terang\", \"pndukung\": \"pendukung\", \"setting\": \"atur\", \"seting\": \"akting\", \"next\": \"lanjut\", \"waspadalah\": \"waspada\", \"gantengsaya\": \"ganteng\", \"parte\": \"partai\", \"nyerang\": \"serang\", \"nipu\": \"tipu\", \"ktipu\": \"tipu\", \"jentelmen\": \"berani\", \"buangbuang\": \"buang\", \"tsangka\": \"tersangka\", \"kurng\": \"kurang\", \"ista\": \"nista\", \"less\": \"kurang\", \"koar\": \"teriak\", \"paranoid\": \"takut\", \"problem\": \"masalah\", \"tahi\": \"kotoran\", \"tirani\": \"tiran\", \"tilep\": \"tilap\", \"happy\": \"bahagia\", \"tak\": \"tidak\", \"penertiban\": \"tertib\", \"uasai\": \"kuasa\", \"mnolak\": \"tolak\", \"trending\": \"trend\", \"taik\": \"tahi\", \"wkwkkw\": \"tertawa\", \"ahokncc\": \"ahok\", \"istaa\": \"nista\", \"benarjujur\": \"jujur\", \"mgkin\": \"mungkin\"}\n",
        "def fix_slangwords(text):\n",
        "    words = text.split()\n",
        "    fixed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if word.lower() in slangwords:\n",
        "            fixed_words.append(slangwords[word.lower()])\n",
        "        else:\n",
        "            fixed_words.append(word)\n",
        "\n",
        "    fixed_text = ' '.join(fixed_words)\n",
        "    return fixed_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxSe-l7JWMA9"
      },
      "source": [
        "**Mengaplikasikan semua function ke clean_df**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gFoDNHiqWMA9"
      },
      "outputs": [],
      "source": [
        "# Membersihkan teks dan menyimpannya di kolom 'text_clean'\n",
        "clean_df['text_clean'] = clean_df['content'].apply(cleaningText)\n",
        "\n",
        "# Mengubah huruf dalam teks menjadi huruf kecil dan menyimpannya di 'text_casefoldingText'\n",
        "clean_df['text_casefoldingText'] = clean_df['text_clean'].apply(casefoldingText)\n",
        "\n",
        "# Mengganti kata-kata slang dengan kata-kata standar dan menyimpannya di 'text_slangwords'\n",
        "clean_df['text_slangwords'] = clean_df['text_casefoldingText'].apply(fix_slangwords)\n",
        "\n",
        "# Memecah teks menjadi token (kata-kata) dan menyimpannya di 'text_tokenizingText'\n",
        "clean_df['text_tokenizingText'] = clean_df['text_slangwords'].apply(tokenizingText)\n",
        "\n",
        "# Menghapus kata-kata stop (kata-kata umum) dan menyimpannya di 'text_stopword'\n",
        "clean_df['text_stopword'] = clean_df['text_tokenizingText'].apply(filteringText)\n",
        "\n",
        "# Menggabungkan token-token menjadi kalimat dan menyimpannya di 'text_akhir'\n",
        "clean_df['text_akhir'] = clean_df['text_stopword'].apply(toSentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "75-ro81IWMA-",
        "outputId": "73a51f05-fdf6-4e07-8051-5b0a0194d773"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       userName  score  \\\n",
              "0                   Bukan Robot      1   \n",
              "1                    marsha Tea      1   \n",
              "2                   Wardi Jafar      1   \n",
              "3                  Nen _tarak92      1   \n",
              "4  Alimurrosyid Budi Rohmansyah      1   \n",
              "\n",
              "                                             content  \\\n",
              "0  aplikasi terjelek kebanyakan nonton iklan nya ...   \n",
              "1  jangan kebanyakan iklan kasian yang ga berlang...   \n",
              "2                       Gak ada film indonesia jelek   \n",
              "3  Aplikasi nya kenapa yah setelah di update kok ...   \n",
              "4                                              burik   \n",
              "\n",
              "                                          text_clean  \\\n",
              "0  aplikasi terjelek kebanyakan nonton iklan nya ...   \n",
              "1  jangan kebanyakan iklan kasian yang ga berlang...   \n",
              "2                       Gak ada film indonesia jelek   \n",
              "3  Aplikasi nya kenapa yah setelah di update kok ...   \n",
              "4                                              burik   \n",
              "\n",
              "                                text_casefoldingText  \\\n",
              "0  aplikasi terjelek kebanyakan nonton iklan nya ...   \n",
              "1  jangan kebanyakan iklan kasian yang ga berlang...   \n",
              "2                       gak ada film indonesia jelek   \n",
              "3  aplikasi nya kenapa yah setelah di update kok ...   \n",
              "4                                              burik   \n",
              "\n",
              "                                     text_slangwords  \\\n",
              "0  aplikasi terjelek kebanyakan nonton iklan nya ...   \n",
              "1  jangan kebanyakan iklan kasian yang ga berlang...   \n",
              "2                       gak ada film indonesia jelek   \n",
              "3  aplikasi nya kenapa yah setelah di update kok ...   \n",
              "4                                              buruk   \n",
              "\n",
              "                                 text_tokenizingText  \\\n",
              "0  [aplikasi, terjelek, kebanyakan, nonton, iklan...   \n",
              "1  [jangan, kebanyakan, iklan, kasian, yang, ga, ...   \n",
              "2                 [gak, ada, film, indonesia, jelek]   \n",
              "3  [aplikasi, nya, kenapa, yah, setelah, di, upda...   \n",
              "4                                            [buruk]   \n",
              "\n",
              "                                       text_stopword  \\\n",
              "0  [aplikasi, terjelek, kebanyakan, nonton, iklan...   \n",
              "1     [kebanyakan, iklan, kasian, berlangganan, vip]   \n",
              "2                           [film, indonesia, jelek]   \n",
              "3                            [aplikasi, yah, update]   \n",
              "4                                            [buruk]   \n",
              "\n",
              "                                          text_akhir  \n",
              "0  aplikasi terjelek kebanyakan nonton iklan dera...  \n",
              "1           kebanyakan iklan kasian berlangganan vip  \n",
              "2                               film indonesia jelek  \n",
              "3                                aplikasi yah update  \n",
              "4                                              buruk  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0773c92f-9a2b-4033-acd9-b97f6e1f2b8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>score</th>\n",
              "      <th>content</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_casefoldingText</th>\n",
              "      <th>text_slangwords</th>\n",
              "      <th>text_tokenizingText</th>\n",
              "      <th>text_stopword</th>\n",
              "      <th>text_akhir</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bukan Robot</td>\n",
              "      <td>1</td>\n",
              "      <td>aplikasi terjelek kebanyakan nonton iklan nya ...</td>\n",
              "      <td>aplikasi terjelek kebanyakan nonton iklan nya ...</td>\n",
              "      <td>aplikasi terjelek kebanyakan nonton iklan nya ...</td>\n",
              "      <td>aplikasi terjelek kebanyakan nonton iklan nya ...</td>\n",
              "      <td>[aplikasi, terjelek, kebanyakan, nonton, iklan...</td>\n",
              "      <td>[aplikasi, terjelek, kebanyakan, nonton, iklan...</td>\n",
              "      <td>aplikasi terjelek kebanyakan nonton iklan dera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>marsha Tea</td>\n",
              "      <td>1</td>\n",
              "      <td>jangan kebanyakan iklan kasian yang ga berlang...</td>\n",
              "      <td>jangan kebanyakan iklan kasian yang ga berlang...</td>\n",
              "      <td>jangan kebanyakan iklan kasian yang ga berlang...</td>\n",
              "      <td>jangan kebanyakan iklan kasian yang ga berlang...</td>\n",
              "      <td>[jangan, kebanyakan, iklan, kasian, yang, ga, ...</td>\n",
              "      <td>[kebanyakan, iklan, kasian, berlangganan, vip]</td>\n",
              "      <td>kebanyakan iklan kasian berlangganan vip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wardi Jafar</td>\n",
              "      <td>1</td>\n",
              "      <td>Gak ada film indonesia jelek</td>\n",
              "      <td>Gak ada film indonesia jelek</td>\n",
              "      <td>gak ada film indonesia jelek</td>\n",
              "      <td>gak ada film indonesia jelek</td>\n",
              "      <td>[gak, ada, film, indonesia, jelek]</td>\n",
              "      <td>[film, indonesia, jelek]</td>\n",
              "      <td>film indonesia jelek</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nen _tarak92</td>\n",
              "      <td>1</td>\n",
              "      <td>Aplikasi nya kenapa yah setelah di update kok ...</td>\n",
              "      <td>Aplikasi nya kenapa yah setelah di update kok ...</td>\n",
              "      <td>aplikasi nya kenapa yah setelah di update kok ...</td>\n",
              "      <td>aplikasi nya kenapa yah setelah di update kok ...</td>\n",
              "      <td>[aplikasi, nya, kenapa, yah, setelah, di, upda...</td>\n",
              "      <td>[aplikasi, yah, update]</td>\n",
              "      <td>aplikasi yah update</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alimurrosyid Budi Rohmansyah</td>\n",
              "      <td>1</td>\n",
              "      <td>burik</td>\n",
              "      <td>burik</td>\n",
              "      <td>burik</td>\n",
              "      <td>buruk</td>\n",
              "      <td>[buruk]</td>\n",
              "      <td>[buruk]</td>\n",
              "      <td>buruk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0773c92f-9a2b-4033-acd9-b97f6e1f2b8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0773c92f-9a2b-4033-acd9-b97f6e1f2b8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0773c92f-9a2b-4033-acd9-b97f6e1f2b8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8da98143-4e78-4199-b176-7d842f019d76\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8da98143-4e78-4199-b176-7d842f019d76')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8da98143-4e78-4199-b176-7d842f019d76 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clean_df",
              "summary": "{\n  \"name\": \"clean_df\",\n  \"rows\": 11997,\n  \"fields\": [\n    {\n      \"column\": \"userName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11885,\n        \"samples\": [\n          \"Bayu Darmawan\",\n          \"Elahbeauty storefashion\",\n          \"ozi nuskarina\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10813,\n        \"samples\": [\n          \"paket lengkap deh soalnya ada semua\",\n          \"Apa sih CC telat banget\",\n          \"Bagus tp ada vip\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10639,\n        \"samples\": [\n          \"kenapa wetv ini selalu ngelagpatahpatah sinyal lancar dan stabil udahbayar mahal nonton cuma untuk ngelag ngelag doang jadi gak nyaman\",\n          \"Serialnya sering putus tidak dilanjutkan ditengah jalan setelah sekian episode seperti Legenda Para Iblis dunia asing dll\",\n          \"Terlalu lambat respon verifikasi sms\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_casefoldingText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10524,\n        \"samples\": [\n          \"aplikasi yang sekarang jelek sering keluar sendiri pas mau nonton filmnya semoga bisa diperbaharui lagi biar nggak bikin kecewa maaf sementara kasih bintang  dulu\",\n          \"subtitle indonesia tiba\\u00b2 hilang\",\n          \"baguss bangett film film nya juga lengkap walau kadang suka ilang sendiri subtitle nya tapi gakpapa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_slangwords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10495,\n        \"samples\": [\n          \"ga bisa login nunggu kode verifikasi ga muncul\",\n          \"sebenarnya seru tapi entah kenapa iya sinyal saya udh bagus tapi tetap tidak bisa melihat jadi iya sementara saya kasih rating dulu kalau masalah sudah diatasi baru saya naikkan bintangnya\",\n          \"sdh vip tapi donwloatn mlh harus di tonton kuota g bisa off line gimn sih rugi q\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_tokenizingText\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_stopword\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_akhir\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10075,\n        \"samples\": [\n          \"apl jelek\",\n          \"jelek\",\n          \"wetv tolong lahsaya berlangganan vip bulankenapa nonton kupu kupu malam episode nyaalasan berlangganan vipserasa tipu sayaudah vip gk nonton\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "clean_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxzg7o1GWMA-"
      },
      "source": [
        "### **Pelabelan Review apakah positif, neutral, atau negatif**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GzT59dz2WMA-"
      },
      "outputs": [],
      "source": [
        "# Membaca data kamus kata-kata positif dari GitHub\n",
        "lexicon_positive = dict()\n",
        "\n",
        "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_positive.csv')\n",
        "# Mengirim permintaan HTTP untuk mendapatkan file CSV dari GitHub\n",
        "\n",
        "if response.status_code == 200:\n",
        "    # Jika permintaan berhasil\n",
        "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
        "    # Membaca teks respons sebagai file CSV menggunakan pembaca CSV dengan pemisah koma\n",
        "\n",
        "    for row in reader:\n",
        "        # Mengulangi setiap baris dalam file CSV\n",
        "        lexicon_positive[row[0]] = int(row[1])\n",
        "        # Menambahkan kata-kata positif dan skornya ke dalam kamus lexicon_positive\n",
        "else:\n",
        "    print(\"Failed to fetch positive lexicon data\")\n",
        "\n",
        "# Membaca data kamus kata-kata negatif dari GitHub\n",
        "lexicon_negative = dict()\n",
        "\n",
        "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_negative.csv')\n",
        "# Mengirim permintaan HTTP untuk mendapatkan file CSV dari GitHub\n",
        "\n",
        "if response.status_code == 200:\n",
        "    # Jika permintaan berhasil\n",
        "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
        "    # Membaca teks respons sebagai file CSV menggunakan pembaca CSV dengan pemisah koma\n",
        "\n",
        "    for row in reader:\n",
        "        # Mengulangi setiap baris dalam file CSV\n",
        "        lexicon_negative[row[0]] = int(row[1])\n",
        "        # Menambahkan kata-kata negatif dan skornya dalam kamus lexicon_negative\n",
        "else:\n",
        "    print(\"Failed to fetch negative lexicon data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35Y_g3lSWMA-"
      },
      "source": [
        "**Melakukan analisis sentimen pada teks berbahasa Indonesia menggunakan kamus kata-kata positif dan negatif.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T6W_Q0u4WMA-"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk menentukan polaritas sentimen dari tweet\n",
        "\n",
        "def sentiment_analysis_lexicon_indonesia(text):\n",
        "    #for word in text:\n",
        "\n",
        "    score = 0\n",
        "    # Inisialisasi skor sentimen ke 0\n",
        "\n",
        "    for word in text:\n",
        "        # Mengulangi setiap kata dalam teks\n",
        "\n",
        "        if (word in lexicon_positive):\n",
        "            score = score + lexicon_positive[word]\n",
        "            # Jika kata ada dalam kamus positif, tambahkan skornya ke skor sentimen\n",
        "\n",
        "    for word in text:\n",
        "        # Mengulangi setiap kata dalam teks (sekali lagi)\n",
        "\n",
        "        if (word in lexicon_negative):\n",
        "            score = score + lexicon_negative[word]\n",
        "            # Jika kata ada dalam kamus negatif, kurangkan skornya dari skor sentimen\n",
        "\n",
        "    polarity=''\n",
        "    # Inisialisasi variabel polaritas\n",
        "\n",
        "    if (score > 0.5):\n",
        "        polarity = 'positive'\n",
        "        # Jika skor sentimen lebih besar atau sama dengan 0, maka polaritas adalah positif\n",
        "    elif (score < -0.5):\n",
        "        polarity = 'negative'\n",
        "        # Jika skor sentimen kurang dari 0, maka polaritas adalah negatif\n",
        "    else:\n",
        "        polarity = 'neutral'\n",
        "    # Ini adalah bagian yang bisa digunakan untuk menentukan polaritas netral jika diperlukan\n",
        "\n",
        "    return score, polarity\n",
        "    # Mengembalikan skor sentimen dan polaritas teks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF0aL0LCWMA-"
      },
      "source": [
        "**Aplikasi polarity ke clean_df**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAuW93LOWMA-",
        "outputId": "cdefd75e-b1b3-475a-e221-04c0c4b57ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "polarity\n",
            "negative    5583\n",
            "positive    3725\n",
            "neutral     2689\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "results = clean_df['text_stopword'].apply(sentiment_analysis_lexicon_indonesia)\n",
        "results = list(zip(*results))\n",
        "clean_df['polarity_score'] = results[0]\n",
        "clean_df['polarity'] = results[1]\n",
        "print(clean_df['polarity'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmP_gqCuWMA_"
      },
      "source": [
        "## **Ekstraksi Fitur**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx-VTSkRWMA_"
      },
      "source": [
        "**Menggunakan TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lTheAlaMWMA_"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Pisahkan data menjadi fitur (tweet) dan label (sentimen)\n",
        "X = clean_df['text_akhir']\n",
        "y = clean_df['polarity']\n",
        "\n",
        "# Ekstraksi fitur dengan TF-IDF\n",
        "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=5000, min_df=17, max_df=0.8 ) # Baru\n",
        "# tfidf = TfidfVectorizer(max_features=200, min_df=17, max_df=0.8 ) # Asal\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "# Konversi hasil ekstraksi fitur menjadi dataframe\n",
        "features_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Menampilkan hasil ekstraksi fitur\n",
        "features_tfidf_df\n",
        "\n",
        "# Bagi data menjadi data latih dan data uji\n",
        "X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM_0khLcWMA_"
      },
      "source": [
        "**Menggunakan BERT (Bidirectional Encoder Representations from Transformers)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l_wyaQnJWMA_"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxUfBPSrWMA_",
        "outputId": "fd206c96-94af-4755-d446-80fe3d2616d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks terpanjang:\n",
            "userName                                             Quthubul Aktab Putra\n",
            "score                                                                   5\n",
            "content                 Wetv top bgt,tapi kalo bisa cepatin dong upgra...\n",
            "text_clean              Wetv top bgttapi kalo bisa cepatin dong upgrad...\n",
            "text_casefoldingText    wetv top bgttapi kalo bisa cepatin dong upgrad...\n",
            "text_slangwords         wetv top bgttapi kalau bisa cepatin dong upgra...\n",
            "text_tokenizingText     [wetv, top, bgttapi, kalau, bisa, cepatin, don...\n",
            "text_stopword           [wetv, top, bgttapi, cepatin, upgrade, film, a...\n",
            "text_akhir              wetv top bgttapi cepatin upgrade film akufilm ...\n",
            "polarity_score                                                          5\n",
            "polarity                                                         positive\n",
            "Name: 11490, dtype: object\n",
            "Statistik panjang token:\n",
            "count    11997.000000\n",
            "mean        17.116779\n",
            "std         16.930722\n",
            "min          0.000000\n",
            "25%          5.000000\n",
            "50%         12.000000\n",
            "75%         24.000000\n",
            "max        137.000000\n",
            "Name: text_akhir, dtype: float64\n",
            "Panjang token teks terpanjang: 137\n"
          ]
        }
      ],
      "source": [
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Menghitung panjang token untuk setiap teks dalam dataset\n",
        "token_lengths = clean_df['text_akhir'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
        "\n",
        "# Menampilkan 5 teks dengan panjang token terbesar\n",
        "longest_texts = clean_df.iloc[token_lengths.idxmax()]  # Ambil teks terpanjang berdasarkan token length\n",
        "print(\"Teks terpanjang:\")\n",
        "print(longest_texts)\n",
        "\n",
        "# Menampilkan statistik distribusi panjang token\n",
        "print(\"Statistik panjang token:\")\n",
        "print(token_lengths.describe())\n",
        "\n",
        "# Menampilkan panjang token teks dengan panjang token terbesar\n",
        "print(\"Panjang token teks terpanjang:\", token_lengths.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3HfB8TKWMA_",
        "outputId": "7cb1f27d-600a-4004-a086-bff6c72270cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11997, 1, 1536)\n",
            "[[[ 0.3075569   0.24962315 -0.9208204  ... -1.1219256  -0.9290605\n",
            "    1.0648259 ]]\n",
            "\n",
            " [[-1.7188449  -0.4695904  -1.0507127  ... -0.37796965 -1.1558845\n",
            "    0.6552159 ]]\n",
            "\n",
            " [[ 0.06584504  0.27519247 -1.5227158  ... -1.1146705  -0.83636093\n",
            "    0.8185787 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.20543647  0.28220174 -1.3938137  ... -0.05330058  0.25038487\n",
            "    1.177689  ]]\n",
            "\n",
            " [[-0.09421083  0.25189725  0.3470116  ... -1.0904464  -0.08978462\n",
            "   -0.19376439]]\n",
            "\n",
            " [[-0.01185349 -0.7163656  -0.74748695 ... -0.6421587   0.1102407\n",
            "   -0.25964674]]]\n",
            "                       userName  score  \\\n",
            "0                   Bukan Robot    1.0   \n",
            "1                    marsha Tea    1.0   \n",
            "2                   Wardi Jafar    1.0   \n",
            "3                  Nen _tarak92    1.0   \n",
            "4  Alimurrosyid Budi Rohmansyah    1.0   \n",
            "\n",
            "                                             content  \\\n",
            "0  aplikasi terjelek kebanyakan nonton iklan nya ...   \n",
            "1  jangan kebanyakan iklan kasian yang ga berlang...   \n",
            "2                       Gak ada film indonesia jelek   \n",
            "3  Aplikasi nya kenapa yah setelah di update kok ...   \n",
            "4                                              burik   \n",
            "\n",
            "                                          text_clean  \\\n",
            "0  aplikasi terjelek kebanyakan nonton iklan nya ...   \n",
            "1  jangan kebanyakan iklan kasian yang ga berlang...   \n",
            "2                       Gak ada film indonesia jelek   \n",
            "3  Aplikasi nya kenapa yah setelah di update kok ...   \n",
            "4                                              burik   \n",
            "\n",
            "                                text_casefoldingText  \\\n",
            "0  aplikasi terjelek kebanyakan nonton iklan nya ...   \n",
            "1  jangan kebanyakan iklan kasian yang ga berlang...   \n",
            "2                       gak ada film indonesia jelek   \n",
            "3  aplikasi nya kenapa yah setelah di update kok ...   \n",
            "4                                              burik   \n",
            "\n",
            "                                     text_slangwords  \\\n",
            "0  aplikasi terjelek kebanyakan nonton iklan nya ...   \n",
            "1  jangan kebanyakan iklan kasian yang ga berlang...   \n",
            "2                       gak ada film indonesia jelek   \n",
            "3  aplikasi nya kenapa yah setelah di update kok ...   \n",
            "4                                              buruk   \n",
            "\n",
            "                                 text_tokenizingText  \\\n",
            "0  [aplikasi, terjelek, kebanyakan, nonton, iklan...   \n",
            "1  [jangan, kebanyakan, iklan, kasian, yang, ga, ...   \n",
            "2                 [gak, ada, film, indonesia, jelek]   \n",
            "3  [aplikasi, nya, kenapa, yah, setelah, di, upda...   \n",
            "4                                            [buruk]   \n",
            "\n",
            "                                       text_stopword  \\\n",
            "0  [aplikasi, terjelek, kebanyakan, nonton, iklan...   \n",
            "1     [kebanyakan, iklan, kasian, berlangganan, vip]   \n",
            "2                           [film, indonesia, jelek]   \n",
            "3                            [aplikasi, yah, update]   \n",
            "4                                            [buruk]   \n",
            "\n",
            "                                          text_akhir  polarity_score  ...  \\\n",
            "0  aplikasi terjelek kebanyakan nonton iklan dera...            -4.0  ...   \n",
            "1           kebanyakan iklan kasian berlangganan vip             1.0  ...   \n",
            "2                               film indonesia jelek            -5.0  ...   \n",
            "3                                aplikasi yah update            -4.0  ...   \n",
            "4                                              buruk            -5.0  ...   \n",
            "\n",
            "  feature_1526  feature_1527  feature_1528  feature_1529  feature_1530  \\\n",
            "0     0.559030     -0.751859      0.280849     -1.347455     -1.931818   \n",
            "1    -0.738056     -1.643728      0.265884     -1.215565     -0.950807   \n",
            "2     0.674366     -1.405495     -0.461714     -1.405456     -0.515808   \n",
            "3     1.012286     -1.338579      0.583770     -0.468629     -1.719892   \n",
            "4    -0.737116     -0.503032      0.757445     -1.683875     -1.209674   \n",
            "\n",
            "   feature_1531  feature_1532  feature_1533  feature_1534  feature_1535  \n",
            "0     -0.467495     -0.462405     -1.121926     -0.929061      1.064826  \n",
            "1     -0.019120     -0.336658     -0.377970     -1.155885      0.655216  \n",
            "2      0.432902     -0.180314     -1.114671     -0.836361      0.818579  \n",
            "3      0.033605     -0.260354      0.930901     -0.481090      0.619568  \n",
            "4      1.951821      0.076712      0.138100     -0.000233     -0.057571  \n",
            "\n",
            "[5 rows x 1547 columns]\n"
          ]
        }
      ],
      "source": [
        "# Memuat tokenizer dan model pre-trained BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('indolem/indobert-base-uncased')  # Gunakan model Indonesia jika diperlukan\n",
        "model = BertModel.from_pretrained('indolem/indobert-base-uncased')\n",
        "\n",
        "# Tentukan perangkat (GPU atau CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Pindahkan model ke perangkat yang sesuai (GPU atau CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Fungsi untuk mengubah teks menjadi vektor menggunakan BERT\n",
        "def encode(text):\n",
        "    # Tokenisasi teks dan konversi ke tensor\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=137)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Forward pass tanpa gradient\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Ambil [CLS] token dan mean pooling dari last hidden state\n",
        "    last_hidden_state = outputs.last_hidden_state  # Shape: (1, seq_len, hidden_size)\n",
        "    cls_token = last_hidden_state[:, 0, :]  # Ambil token [CLS], shape: (1, hidden_size)\n",
        "    mean_pooling = last_hidden_state.mean(dim=1)  # Mean pooling, shape: (1, hidden_size)\n",
        "\n",
        "    # Gabungkan keduanya jadi 1 vektor (shape: (1, 1536))\n",
        "    combined = torch.cat((cls_token, mean_pooling), dim=1)\n",
        "\n",
        "    # Kembalikan sebagai numpy array\n",
        "    return combined.detach().cpu().numpy()\n",
        "\n",
        "# Ekstraksi fitur dari kolom 'text_akhir' di clean_df\n",
        "X_bert = np.array([encode(text) for text in clean_df['text_akhir']])\n",
        "\n",
        "# Melihat hasilnya\n",
        "print(X_bert.shape)  # Menampilkan ukuran vektor hasil ekstraksi fitur\n",
        "print(X_bert)  # Menampilkan vektor hasil ekstraksi fitur\n",
        "\n",
        "X_bert_reshaped = X_bert.squeeze(axis=1)\n",
        "\n",
        "# Menambahkan hasil ekstraksi BERT ke dalam DataFrame\n",
        "df_bert = pd.DataFrame(X_bert_reshaped)\n",
        "df_bert.columns = [f'feature_{i}' for i in range(X_bert_reshaped.shape[1])]\n",
        "\n",
        "# Gabungkan DataFrame asli dengan fitur BERT\n",
        "bert_df_combined = pd.concat([clean_df, df_bert], axis=1)\n",
        "\n",
        "# Menampilkan DataFrame yang telah digabungkan\n",
        "print(bert_df_combined.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Percobaan Model**"
      ],
      "metadata": {
        "id": "MXOdV5hJUG-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Random Forest TF-IDF dan BERT**"
      ],
      "metadata": {
        "id": "UCP1bXSPaq9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Cd0afQlUavj0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Model Random Forest dengan Fitur TF-IDF**"
      ],
      "metadata": {
        "id": "V37GqytOa1ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Inisialisasi LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Transform label (y) ke bentuk numerik\n",
        "y_encoded = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "5vR2MU1ayC46"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(X_tfidf, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inisialisasi model Random Forest\n",
        "rf_tfidf = RandomForestClassifier(n_estimators=1000, max_depth=50, min_samples_split=5, random_state=42)\n",
        "\n",
        "# Melakukan cross-validation dengan 5 fold\n",
        "cv_scores = cross_val_score(rf_tfidf, X_tfidf, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Menampilkan hasil cross-validation\n",
        "print(f\"Cross-validation accuracy scores: {cv_scores}\")\n",
        "print(f\"Mean cross-validation accuracy: {cv_scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEuo6RDHayq5",
        "outputId": "b9ce238f-2c0d-4c57-bf77-df6536a1a349"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation accuracy scores: [0.795      0.79916667 0.79866611 0.80408504 0.79283035]\n",
            "Mean cross-validation accuracy: 0.797949631791024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Bagi data menjadi data latih dan data uji (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inisialisasi model Logistic Regression dengan parameter terbaik\n",
        "best_model = LogisticRegression(C=4.8, max_iter=200, solver='lbfgs', multi_class='ovr', random_state=42)\n",
        "\n",
        "# Latih model dengan data latih\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi hasil pada data uji\n",
        "y_best_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluasi model dengan akurasi\n",
        "print(\"Evaluasi Model Logistic Regression dengan Parameter Terbaik:\")\n",
        "print(\"Akurasi:\", accuracy_score(y_test, y_best_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOhN6z4fnMcD",
        "outputId": "7177bf9d-4857-400d-e7ce-10daa90756e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluasi Model Logistic Regression dengan Parameter Terbaik:\n",
            "Akurasi: 0.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [4.5, 4.8, 4.3],\n",
        "    'solver': ['liblinear', 'lbfgs'],\n",
        "    'max_iter': [200, 180, 220],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(multi_class='ovr', random_state=42), param_grid, cv=5)\n",
        "grid_search.fit(X_tfidf, y)\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation score: \", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD_JieLpnszv",
        "outputId": "6fad93a6-9234-4ec5-df53-f348b84eff3b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'C': 4.8, 'max_iter': 200, 'solver': 'lbfgs'}\n",
            "Best cross-validation score:  0.8627999166319299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Model Random Forest dengan Fitur BERT**"
      ],
      "metadata": {
        "id": "kmcLQDNEa5xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagi data menjadi data latih dan data uji (80/20)\n",
        "X_bert_train, X_bert_test, y_bert_train, y_bert_test = train_test_split(X_bert_reshaped, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inisialisasi model Random Forest\n",
        "rf_bert = RandomForestClassifier(n_estimators=500, max_depth=50, min_samples_split=20, random_state=42)\n",
        "\n",
        "# Melatih model dengan data latih\n",
        "rf_bert.fit(X_bert_train, y_bert_train)\n",
        "\n",
        "# Prediksi hasil pada data uji\n",
        "y_bert_pred = rf_bert.predict(X_bert_test)\n",
        "\n",
        "# Menampilkan hasil evaluasi\n",
        "print(\"Evaluasi Model Random Forest dengan Fitur BERT:\")\n",
        "print(\"Akurasi:\", accuracy_score(y_bert_test, y_bert_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXMSujYrbB2o",
        "outputId": "ea50b691-a55a-49e6-c3a9-a1097f2d29f8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluasi Model Random Forest dengan Fitur BERT:\n",
            "Akurasi: 0.635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Menggunakan Algoritma Deep Learning dengan TF-IDF**"
      ],
      "metadata": {
        "id": "zlk2k53Nbn_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagi data menjadi data latih dan data uji (80/20)\n",
        "X_dl_train, X_dl_test, y_dl_train, y_dl_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OIwkGFJhbtvk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode kategori dengan label encoder**"
      ],
      "metadata": {
        "id": "0Gl_sLdCdx8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Inisialisasi encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit dan transform label ke bentuk numerik\n",
        "y_dl_train = label_encoder.fit_transform(y_dl_train)\n",
        "y_dl_test = label_encoder.transform(y_dl_test)\n",
        "\n",
        "# Langkah 2: Ubah ke one-hot\n",
        "y_dl_train_oh = to_categorical(y_dl_train)\n",
        "y_dl_test_oh = to_categorical(y_dl_test)"
      ],
      "metadata": {
        "id": "mAFSHvGXdxj0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_dl_train = X_dl_train.toarray().astype('float32')\n",
        "X_dl_test = X_dl_test.toarray().astype('float32')"
      ],
      "metadata": {
        "id": "56nNGXYEdmF4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "# Misalnya ingin kurangi ke 100 fitur\n",
        "svd = TruncatedSVD(n_components=400, random_state=42)\n",
        "\n",
        "# Fit di training, transform di training dan testing\n",
        "X_train_svd = svd.fit_transform(X_dl_train)\n",
        "X_test_svd = svd.transform(X_dl_test)"
      ],
      "metadata": {
        "id": "ldiHKAq9yZzx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.0001), input_shape=(X_tfidf.shape[1],)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "    # tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
        "    # tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LeKGkFmcjEk",
        "outputId": "cfd87aed-39d0-4bde-a051-b33bd53b612e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_dl_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INCtH8zCdasb",
        "outputId": "30f910fd-d67a-44be-c8ed-79ea868efeaf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, mode='max', restore_best_weights=True)\n",
        "]\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0003), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# history3 = model.fit(X_dl_train, y_dl_train, epochs=100, batch_size=16, callbacks=callbacks, validation_data=(X_dl_test, y_dl_test))\n",
        "history3 = model.fit(X_dl_train, y_dl_train, epochs=100, batch_size=128, validation_data=(X_dl_test, y_dl_test))\n",
        "#epoch 20 = 0.8745\n",
        "#epoch 30 = 0.9023\n",
        "#epoch 40 dropout 0.5 = 0.8957 0.7844\n",
        "#epoch 40 dropout 0.3 = 0.9237 0.7783\n",
        "#epoch 40 dropout 0.3 L2 regu = 0.8974 0.7828\n",
        "#epoch 40 dropout 0.3 L2 regu Smaller Dense = 0.8524 0.7964\n",
        "#epoch 100 Early stoping Layer 128 64 = accuracy: 0.8541 0.7986\n",
        "#epoch 100 Early stoping Layer 256 128 ="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvtTTK0tctkA",
        "outputId": "7525677f-8ee1-45f1-e794-f104eb556513"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3512 - loss: 1.5232 - val_accuracy: 0.3100 - val_loss: 1.1126\n",
            "Epoch 2/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4468 - loss: 1.2153 - val_accuracy: 0.3100 - val_loss: 1.1112\n",
            "Epoch 3/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5129 - loss: 1.0685 - val_accuracy: 0.3688 - val_loss: 1.1062\n",
            "Epoch 4/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5631 - loss: 0.9526 - val_accuracy: 0.4950 - val_loss: 1.0915\n",
            "Epoch 5/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6174 - loss: 0.8462 - val_accuracy: 0.6617 - val_loss: 1.0457\n",
            "Epoch 6/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6514 - loss: 0.7999 - val_accuracy: 0.7121 - val_loss: 0.9547\n",
            "Epoch 7/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6879 - loss: 0.7468 - val_accuracy: 0.7425 - val_loss: 0.8364\n",
            "Epoch 8/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7038 - loss: 0.7257 - val_accuracy: 0.7650 - val_loss: 0.7330\n",
            "Epoch 9/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7453 - loss: 0.6611 - val_accuracy: 0.7754 - val_loss: 0.6638\n",
            "Epoch 10/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7752 - loss: 0.6167 - val_accuracy: 0.7867 - val_loss: 0.6217\n",
            "Epoch 11/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.6010 - val_accuracy: 0.7971 - val_loss: 0.5941\n",
            "Epoch 12/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7957 - loss: 0.5748 - val_accuracy: 0.8037 - val_loss: 0.5746\n",
            "Epoch 13/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8069 - loss: 0.5518 - val_accuracy: 0.8104 - val_loss: 0.5574\n",
            "Epoch 14/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8143 - loss: 0.5271 - val_accuracy: 0.8133 - val_loss: 0.5435\n",
            "Epoch 15/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8289 - loss: 0.4980 - val_accuracy: 0.8196 - val_loss: 0.5333\n",
            "Epoch 16/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8360 - loss: 0.4925 - val_accuracy: 0.8221 - val_loss: 0.5246\n",
            "Epoch 17/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8382 - loss: 0.4697 - val_accuracy: 0.8271 - val_loss: 0.5192\n",
            "Epoch 18/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.4391 - val_accuracy: 0.8271 - val_loss: 0.5120\n",
            "Epoch 19/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8497 - loss: 0.4588 - val_accuracy: 0.8288 - val_loss: 0.5088\n",
            "Epoch 20/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8567 - loss: 0.4384 - val_accuracy: 0.8333 - val_loss: 0.5030\n",
            "Epoch 21/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8606 - loss: 0.4250 - val_accuracy: 0.8313 - val_loss: 0.5012\n",
            "Epoch 22/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8605 - loss: 0.4107 - val_accuracy: 0.8325 - val_loss: 0.4991\n",
            "Epoch 23/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8701 - loss: 0.4037 - val_accuracy: 0.8358 - val_loss: 0.4981\n",
            "Epoch 24/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8672 - loss: 0.4044 - val_accuracy: 0.8358 - val_loss: 0.4972\n",
            "Epoch 25/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8752 - loss: 0.3802 - val_accuracy: 0.8383 - val_loss: 0.4970\n",
            "Epoch 26/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8784 - loss: 0.3857 - val_accuracy: 0.8392 - val_loss: 0.4941\n",
            "Epoch 27/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8824 - loss: 0.3771 - val_accuracy: 0.8354 - val_loss: 0.4952\n",
            "Epoch 28/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8871 - loss: 0.3652 - val_accuracy: 0.8392 - val_loss: 0.4958\n",
            "Epoch 29/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8883 - loss: 0.3660 - val_accuracy: 0.8367 - val_loss: 0.4971\n",
            "Epoch 30/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8921 - loss: 0.3475 - val_accuracy: 0.8383 - val_loss: 0.4998\n",
            "Epoch 31/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8960 - loss: 0.3318 - val_accuracy: 0.8379 - val_loss: 0.5020\n",
            "Epoch 32/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9009 - loss: 0.3314 - val_accuracy: 0.8400 - val_loss: 0.5031\n",
            "Epoch 33/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8958 - loss: 0.3402 - val_accuracy: 0.8388 - val_loss: 0.5031\n",
            "Epoch 34/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9051 - loss: 0.3097 - val_accuracy: 0.8367 - val_loss: 0.5069\n",
            "Epoch 35/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9038 - loss: 0.3215 - val_accuracy: 0.8363 - val_loss: 0.5115\n",
            "Epoch 36/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9032 - loss: 0.3086 - val_accuracy: 0.8379 - val_loss: 0.5124\n",
            "Epoch 37/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9045 - loss: 0.3074 - val_accuracy: 0.8379 - val_loss: 0.5161\n",
            "Epoch 38/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9081 - loss: 0.3100 - val_accuracy: 0.8379 - val_loss: 0.5161\n",
            "Epoch 39/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2958 - val_accuracy: 0.8363 - val_loss: 0.5194\n",
            "Epoch 40/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9115 - loss: 0.2857 - val_accuracy: 0.8379 - val_loss: 0.5255\n",
            "Epoch 41/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9186 - loss: 0.2811 - val_accuracy: 0.8392 - val_loss: 0.5275\n",
            "Epoch 42/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9071 - loss: 0.2968 - val_accuracy: 0.8400 - val_loss: 0.5311\n",
            "Epoch 43/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9167 - loss: 0.2858 - val_accuracy: 0.8383 - val_loss: 0.5331\n",
            "Epoch 44/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9175 - loss: 0.2791 - val_accuracy: 0.8383 - val_loss: 0.5369\n",
            "Epoch 45/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9210 - loss: 0.2693 - val_accuracy: 0.8396 - val_loss: 0.5401\n",
            "Epoch 46/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9209 - loss: 0.2600 - val_accuracy: 0.8400 - val_loss: 0.5434\n",
            "Epoch 47/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9185 - loss: 0.2692 - val_accuracy: 0.8388 - val_loss: 0.5500\n",
            "Epoch 48/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9200 - loss: 0.2617 - val_accuracy: 0.8358 - val_loss: 0.5520\n",
            "Epoch 49/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9209 - loss: 0.2708 - val_accuracy: 0.8375 - val_loss: 0.5589\n",
            "Epoch 50/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9310 - loss: 0.2468 - val_accuracy: 0.8354 - val_loss: 0.5594\n",
            "Epoch 51/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9292 - loss: 0.2489 - val_accuracy: 0.8375 - val_loss: 0.5627\n",
            "Epoch 52/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.2441 - val_accuracy: 0.8379 - val_loss: 0.5611\n",
            "Epoch 53/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2466 - val_accuracy: 0.8379 - val_loss: 0.5643\n",
            "Epoch 54/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9322 - loss: 0.2537 - val_accuracy: 0.8396 - val_loss: 0.5669\n",
            "Epoch 55/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9296 - loss: 0.2565 - val_accuracy: 0.8354 - val_loss: 0.5710\n",
            "Epoch 56/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9341 - loss: 0.2394 - val_accuracy: 0.8338 - val_loss: 0.5742\n",
            "Epoch 57/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9338 - loss: 0.2328 - val_accuracy: 0.8358 - val_loss: 0.5808\n",
            "Epoch 58/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9322 - loss: 0.2429 - val_accuracy: 0.8404 - val_loss: 0.5816\n",
            "Epoch 59/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9375 - loss: 0.2211 - val_accuracy: 0.8358 - val_loss: 0.5851\n",
            "Epoch 60/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9409 - loss: 0.2160 - val_accuracy: 0.8379 - val_loss: 0.5925\n",
            "Epoch 61/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9398 - loss: 0.2079 - val_accuracy: 0.8367 - val_loss: 0.5992\n",
            "Epoch 62/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9340 - loss: 0.2345 - val_accuracy: 0.8383 - val_loss: 0.6036\n",
            "Epoch 63/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9372 - loss: 0.2160 - val_accuracy: 0.8350 - val_loss: 0.6045\n",
            "Epoch 64/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9352 - loss: 0.2224 - val_accuracy: 0.8342 - val_loss: 0.6102\n",
            "Epoch 65/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9407 - loss: 0.2128 - val_accuracy: 0.8379 - val_loss: 0.6150\n",
            "Epoch 66/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9423 - loss: 0.2077 - val_accuracy: 0.8363 - val_loss: 0.6194\n",
            "Epoch 67/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9379 - loss: 0.2239 - val_accuracy: 0.8350 - val_loss: 0.6245\n",
            "Epoch 68/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9414 - loss: 0.2059 - val_accuracy: 0.8350 - val_loss: 0.6256\n",
            "Epoch 69/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9360 - loss: 0.2249 - val_accuracy: 0.8354 - val_loss: 0.6257\n",
            "Epoch 70/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9417 - loss: 0.2056 - val_accuracy: 0.8342 - val_loss: 0.6330\n",
            "Epoch 71/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9460 - loss: 0.2111 - val_accuracy: 0.8329 - val_loss: 0.6347\n",
            "Epoch 72/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.2005 - val_accuracy: 0.8350 - val_loss: 0.6404\n",
            "Epoch 73/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9408 - loss: 0.2068 - val_accuracy: 0.8300 - val_loss: 0.6466\n",
            "Epoch 74/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.2058 - val_accuracy: 0.8308 - val_loss: 0.6503\n",
            "Epoch 75/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9464 - loss: 0.2004 - val_accuracy: 0.8321 - val_loss: 0.6550\n",
            "Epoch 76/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.1991 - val_accuracy: 0.8317 - val_loss: 0.6533\n",
            "Epoch 77/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9459 - loss: 0.2025 - val_accuracy: 0.8313 - val_loss: 0.6538\n",
            "Epoch 78/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9470 - loss: 0.2012 - val_accuracy: 0.8321 - val_loss: 0.6619\n",
            "Epoch 79/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9477 - loss: 0.1937 - val_accuracy: 0.8329 - val_loss: 0.6668\n",
            "Epoch 80/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9488 - loss: 0.1931 - val_accuracy: 0.8325 - val_loss: 0.6664\n",
            "Epoch 81/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9450 - loss: 0.2022 - val_accuracy: 0.8338 - val_loss: 0.6641\n",
            "Epoch 82/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9460 - loss: 0.1949 - val_accuracy: 0.8338 - val_loss: 0.6656\n",
            "Epoch 83/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9489 - loss: 0.1925 - val_accuracy: 0.8333 - val_loss: 0.6710\n",
            "Epoch 84/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9507 - loss: 0.1804 - val_accuracy: 0.8329 - val_loss: 0.6727\n",
            "Epoch 85/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9537 - loss: 0.1810 - val_accuracy: 0.8333 - val_loss: 0.6759\n",
            "Epoch 86/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.1904 - val_accuracy: 0.8338 - val_loss: 0.6804\n",
            "Epoch 87/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9507 - loss: 0.1871 - val_accuracy: 0.8342 - val_loss: 0.6800\n",
            "Epoch 88/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9520 - loss: 0.1806 - val_accuracy: 0.8342 - val_loss: 0.6816\n",
            "Epoch 89/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.1900 - val_accuracy: 0.8346 - val_loss: 0.6883\n",
            "Epoch 90/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9531 - loss: 0.1847 - val_accuracy: 0.8329 - val_loss: 0.6890\n",
            "Epoch 91/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.1926 - val_accuracy: 0.8321 - val_loss: 0.6925\n",
            "Epoch 92/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9513 - loss: 0.1912 - val_accuracy: 0.8350 - val_loss: 0.6927\n",
            "Epoch 93/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9542 - loss: 0.1746 - val_accuracy: 0.8333 - val_loss: 0.7039\n",
            "Epoch 94/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.1733 - val_accuracy: 0.8329 - val_loss: 0.7070\n",
            "Epoch 95/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9524 - loss: 0.1874 - val_accuracy: 0.8325 - val_loss: 0.7121\n",
            "Epoch 96/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9489 - loss: 0.1889 - val_accuracy: 0.8342 - val_loss: 0.7176\n",
            "Epoch 97/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9525 - loss: 0.1796 - val_accuracy: 0.8342 - val_loss: 0.7225\n",
            "Epoch 98/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9553 - loss: 0.1822 - val_accuracy: 0.8321 - val_loss: 0.7209\n",
            "Epoch 99/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9566 - loss: 0.1709 - val_accuracy: 0.8283 - val_loss: 0.7297\n",
            "Epoch 100/100\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9571 - loss: 0.1635 - val_accuracy: 0.8317 - val_loss: 0.7350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoding**"
      ],
      "metadata": {
        "id": "yEogNvI3iGuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, mode='max', restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, mode='max')\n",
        "]\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# history76 = model.fit(X_dl_train, y_dl_train_oh, epochs=100, batch_size=128, callbacks=callbacks, validation_data=(X_dl_test, y_dl_test_oh))\n",
        "history76 = model.fit(X_dl_train, y_dl_train_oh, epochs=100, batch_size=32, validation_data=(X_dl_test, y_dl_test_oh))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDuQPQIYh8EU",
        "outputId": "fcd3129c-a7f6-46f9-f8f4-d71740574557"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9407 - loss: 0.2158 - val_accuracy: 0.8308 - val_loss: 0.7515\n",
            "Epoch 2/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9443 - loss: 0.2166 - val_accuracy: 0.8300 - val_loss: 0.7621\n",
            "Epoch 3/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9335 - loss: 0.2418 - val_accuracy: 0.8242 - val_loss: 0.7525\n",
            "Epoch 4/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9361 - loss: 0.2228 - val_accuracy: 0.8238 - val_loss: 0.7781\n",
            "Epoch 5/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9365 - loss: 0.2274 - val_accuracy: 0.8342 - val_loss: 0.7506\n",
            "Epoch 6/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9341 - loss: 0.2413 - val_accuracy: 0.8279 - val_loss: 0.7284\n",
            "Epoch 7/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9303 - loss: 0.2418 - val_accuracy: 0.8300 - val_loss: 0.7330\n",
            "Epoch 8/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9311 - loss: 0.2499 - val_accuracy: 0.8283 - val_loss: 0.7415\n",
            "Epoch 9/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9295 - loss: 0.2554 - val_accuracy: 0.8263 - val_loss: 0.7250\n",
            "Epoch 10/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.2633 - val_accuracy: 0.8267 - val_loss: 0.7443\n",
            "Epoch 11/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9264 - loss: 0.2612 - val_accuracy: 0.8258 - val_loss: 0.7321\n",
            "Epoch 12/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9267 - loss: 0.2538 - val_accuracy: 0.8275 - val_loss: 0.7142\n",
            "Epoch 13/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9193 - loss: 0.2798 - val_accuracy: 0.8296 - val_loss: 0.7302\n",
            "Epoch 14/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9237 - loss: 0.2634 - val_accuracy: 0.8292 - val_loss: 0.7306\n",
            "Epoch 15/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.2648 - val_accuracy: 0.8304 - val_loss: 0.7326\n",
            "Epoch 16/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9256 - loss: 0.2851 - val_accuracy: 0.8225 - val_loss: 0.7201\n",
            "Epoch 17/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9228 - loss: 0.2615 - val_accuracy: 0.8283 - val_loss: 0.7152\n",
            "Epoch 18/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9220 - loss: 0.2887 - val_accuracy: 0.8258 - val_loss: 0.7279\n",
            "Epoch 19/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9284 - loss: 0.2527 - val_accuracy: 0.8225 - val_loss: 0.7301\n",
            "Epoch 20/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9231 - loss: 0.2809 - val_accuracy: 0.8267 - val_loss: 0.7006\n",
            "Epoch 21/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.2704 - val_accuracy: 0.8275 - val_loss: 0.6939\n",
            "Epoch 22/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9270 - loss: 0.2536 - val_accuracy: 0.8292 - val_loss: 0.6915\n",
            "Epoch 23/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9153 - loss: 0.2797 - val_accuracy: 0.8271 - val_loss: 0.6934\n",
            "Epoch 24/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9195 - loss: 0.2814 - val_accuracy: 0.8238 - val_loss: 0.6879\n",
            "Epoch 25/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.2738 - val_accuracy: 0.8267 - val_loss: 0.6935\n",
            "Epoch 26/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2771 - val_accuracy: 0.8321 - val_loss: 0.6762\n",
            "Epoch 27/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.2740 - val_accuracy: 0.8308 - val_loss: 0.6748\n",
            "Epoch 28/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.2732 - val_accuracy: 0.8242 - val_loss: 0.6747\n",
            "Epoch 29/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9252 - loss: 0.2665 - val_accuracy: 0.8271 - val_loss: 0.6822\n",
            "Epoch 30/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.2731 - val_accuracy: 0.8288 - val_loss: 0.6878\n",
            "Epoch 31/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9212 - loss: 0.2820 - val_accuracy: 0.8313 - val_loss: 0.6665\n",
            "Epoch 32/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9263 - loss: 0.2638 - val_accuracy: 0.8367 - val_loss: 0.6764\n",
            "Epoch 33/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2682 - val_accuracy: 0.8346 - val_loss: 0.6776\n",
            "Epoch 34/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2859 - val_accuracy: 0.8321 - val_loss: 0.6664\n",
            "Epoch 35/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9190 - loss: 0.2749 - val_accuracy: 0.8325 - val_loss: 0.6778\n",
            "Epoch 36/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9267 - loss: 0.2634 - val_accuracy: 0.8304 - val_loss: 0.6818\n",
            "Epoch 37/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9228 - loss: 0.2742 - val_accuracy: 0.8300 - val_loss: 0.6663\n",
            "Epoch 38/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9261 - loss: 0.2603 - val_accuracy: 0.8300 - val_loss: 0.6812\n",
            "Epoch 39/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9173 - loss: 0.2945 - val_accuracy: 0.8342 - val_loss: 0.6589\n",
            "Epoch 40/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.2708 - val_accuracy: 0.8321 - val_loss: 0.6523\n",
            "Epoch 41/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2862 - val_accuracy: 0.8308 - val_loss: 0.6413\n",
            "Epoch 42/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2926 - val_accuracy: 0.8325 - val_loss: 0.6597\n",
            "Epoch 43/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.2657 - val_accuracy: 0.8292 - val_loss: 0.6534\n",
            "Epoch 44/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2874 - val_accuracy: 0.8275 - val_loss: 0.6317\n",
            "Epoch 45/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2842 - val_accuracy: 0.8275 - val_loss: 0.6589\n",
            "Epoch 46/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.2809 - val_accuracy: 0.8321 - val_loss: 0.6583\n",
            "Epoch 47/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9201 - loss: 0.2938 - val_accuracy: 0.8296 - val_loss: 0.6509\n",
            "Epoch 48/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.2915 - val_accuracy: 0.8308 - val_loss: 0.6522\n",
            "Epoch 49/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2892 - val_accuracy: 0.8379 - val_loss: 0.6438\n",
            "Epoch 50/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.2638 - val_accuracy: 0.8321 - val_loss: 0.6594\n",
            "Epoch 51/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9200 - loss: 0.2922 - val_accuracy: 0.8313 - val_loss: 0.6538\n",
            "Epoch 52/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9220 - loss: 0.2680 - val_accuracy: 0.8288 - val_loss: 0.6422\n",
            "Epoch 53/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9223 - loss: 0.2775 - val_accuracy: 0.8288 - val_loss: 0.6490\n",
            "Epoch 54/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.2732 - val_accuracy: 0.8308 - val_loss: 0.6503\n",
            "Epoch 55/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.2628 - val_accuracy: 0.8329 - val_loss: 0.6417\n",
            "Epoch 56/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.2619 - val_accuracy: 0.8338 - val_loss: 0.6467\n",
            "Epoch 57/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9252 - loss: 0.2813 - val_accuracy: 0.8346 - val_loss: 0.6568\n",
            "Epoch 58/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9219 - loss: 0.2890 - val_accuracy: 0.8342 - val_loss: 0.6581\n",
            "Epoch 59/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9222 - loss: 0.2811 - val_accuracy: 0.8375 - val_loss: 0.6732\n",
            "Epoch 60/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.2844 - val_accuracy: 0.8308 - val_loss: 0.6443\n",
            "Epoch 61/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2923 - val_accuracy: 0.8321 - val_loss: 0.6581\n",
            "Epoch 62/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.2759 - val_accuracy: 0.8296 - val_loss: 0.6465\n",
            "Epoch 63/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.2764 - val_accuracy: 0.8371 - val_loss: 0.6464\n",
            "Epoch 64/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9201 - loss: 0.2814 - val_accuracy: 0.8321 - val_loss: 0.6280\n",
            "Epoch 65/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9215 - loss: 0.2737 - val_accuracy: 0.8313 - val_loss: 0.6523\n",
            "Epoch 66/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2783 - val_accuracy: 0.8250 - val_loss: 0.6594\n",
            "Epoch 67/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2703 - val_accuracy: 0.8329 - val_loss: 0.6419\n",
            "Epoch 68/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9197 - loss: 0.2816 - val_accuracy: 0.8317 - val_loss: 0.6450\n",
            "Epoch 69/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.2712 - val_accuracy: 0.8275 - val_loss: 0.6285\n",
            "Epoch 70/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9243 - loss: 0.2706 - val_accuracy: 0.8267 - val_loss: 0.6472\n",
            "Epoch 71/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2930 - val_accuracy: 0.8267 - val_loss: 0.6478\n",
            "Epoch 72/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.2820 - val_accuracy: 0.8350 - val_loss: 0.6409\n",
            "Epoch 73/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9181 - loss: 0.3079 - val_accuracy: 0.8300 - val_loss: 0.6385\n",
            "Epoch 74/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9226 - loss: 0.2844 - val_accuracy: 0.8300 - val_loss: 0.6461\n",
            "Epoch 75/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2778 - val_accuracy: 0.8279 - val_loss: 0.6420\n",
            "Epoch 76/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.2863 - val_accuracy: 0.8304 - val_loss: 0.6397\n",
            "Epoch 77/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.2549 - val_accuracy: 0.8329 - val_loss: 0.6468\n",
            "Epoch 78/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9149 - loss: 0.2936 - val_accuracy: 0.8313 - val_loss: 0.6438\n",
            "Epoch 79/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9254 - loss: 0.2747 - val_accuracy: 0.8271 - val_loss: 0.6488\n",
            "Epoch 80/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2920 - val_accuracy: 0.8271 - val_loss: 0.6662\n",
            "Epoch 81/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.2753 - val_accuracy: 0.8321 - val_loss: 0.6363\n",
            "Epoch 82/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.2695 - val_accuracy: 0.8333 - val_loss: 0.6445\n",
            "Epoch 83/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.2817 - val_accuracy: 0.8358 - val_loss: 0.6441\n",
            "Epoch 84/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.2975 - val_accuracy: 0.8283 - val_loss: 0.6486\n",
            "Epoch 85/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.2737 - val_accuracy: 0.8292 - val_loss: 0.6484\n",
            "Epoch 86/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9246 - loss: 0.2735 - val_accuracy: 0.8321 - val_loss: 0.6413\n",
            "Epoch 87/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.2815 - val_accuracy: 0.8321 - val_loss: 0.6509\n",
            "Epoch 88/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9204 - loss: 0.2841 - val_accuracy: 0.8342 - val_loss: 0.6477\n",
            "Epoch 89/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2868 - val_accuracy: 0.8325 - val_loss: 0.6407\n",
            "Epoch 90/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9184 - loss: 0.2833 - val_accuracy: 0.8379 - val_loss: 0.6458\n",
            "Epoch 91/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9227 - loss: 0.2685 - val_accuracy: 0.8371 - val_loss: 0.6322\n",
            "Epoch 92/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9166 - loss: 0.2877 - val_accuracy: 0.8363 - val_loss: 0.6374\n",
            "Epoch 93/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9215 - loss: 0.2823 - val_accuracy: 0.8321 - val_loss: 0.6370\n",
            "Epoch 94/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9300 - loss: 0.2623 - val_accuracy: 0.8275 - val_loss: 0.6357\n",
            "Epoch 95/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9221 - loss: 0.2730 - val_accuracy: 0.8317 - val_loss: 0.6346\n",
            "Epoch 96/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9218 - loss: 0.2886 - val_accuracy: 0.8367 - val_loss: 0.6327\n",
            "Epoch 97/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.2722 - val_accuracy: 0.8338 - val_loss: 0.6401\n",
            "Epoch 98/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.3083 - val_accuracy: 0.8400 - val_loss: 0.6477\n",
            "Epoch 99/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9205 - loss: 0.2813 - val_accuracy: 0.8333 - val_loss: 0.6423\n",
            "Epoch 100/100\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.2716 - val_accuracy: 0.8421 - val_loss: 0.6291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Model**"
      ],
      "metadata": {
        "id": "ErFzD18YTz5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setelah Fine tuning akhirnya mencapai 85% accuracy**"
      ],
      "metadata": {
        "id": "Ao9qFOEIT5d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stratified K-Fold**"
      ],
      "metadata": {
        "id": "sBLyuHTapJ6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# 1. Encode label\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # y: label asli\n",
        "y_oh = to_categorical(y_encoded)\n",
        "\n",
        "# 2. Konversi fitur ke dense jika masih dalam bentuk sparse matrix\n",
        "X_array = X_tfidf.toarray().astype('float32')\n",
        "\n",
        "# X_array = X_bert_reshaped.astype('float32')\n",
        "\n",
        "# Misalnya ingin kurangi ke 100 fitur\n",
        "svd = TruncatedSVD(n_components=400, random_state=42)\n",
        "\n",
        "# Fit di training, transform di training dan testing\n",
        "X_svd = svd.fit_transform(X_array)\n",
        "\n",
        "# 3. Inisialisasi Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "val_accuracies = []\n",
        "\n",
        "# 4. Loop training per fold\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_array, y_encoded)):\n",
        "    print(f\"\\nFold {fold+1}\")\n",
        "\n",
        "    # X_train_fold, X_val_fold = X_svd[train_idx], X_svd[val_idx]\n",
        "    X_train_fold, X_val_fold = X_array[train_idx], X_array[val_idx]\n",
        "    y_train_fold, y_val_fold = y_oh[train_idx], y_oh[val_idx]\n",
        "\n",
        "    # 5. Bangun model baru untuk setiap fold\n",
        "    model = tf.keras.models.Sequential([\n",
        "    # Layer pertama dengan Regularisasi L2 dan BatchNormalization\n",
        "      tf.keras.layers.Dense(128, activation=None, kernel_regularizer=regularizers.l2(0.0005), input_shape=(X_array.shape[1],), use_bias=False),\n",
        "      # tf.keras.layers.Dense(128, activation=None, kernel_regularizer=regularizers.l2(0.0005), input_shape=(X_svd.shape[1],), use_bias=False),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "      # Layer kedua dengan Regularisasi L2 dan BatchNormalization\n",
        "      tf.keras.layers.Dense(64, activation=None, kernel_regularizer=regularizers.l2(0.0005), use_bias=False),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "      # Layer ketiga dengan Regularisasi L2\n",
        "      tf.keras.layers.Dense(32, activation=None, kernel_regularizer=regularizers.l2(0.0005), use_bias=False),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "      # Output Layer dengan softmax untuk multi-class classification\n",
        "      tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # 6. Compile model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4, decay=1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # 7. Callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, mode='max'),\n",
        "        ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "    ]\n",
        "\n",
        "    # 8. Train model\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        epochs=150,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 9. Simpan akurasi\n",
        "    val_acc = max(history.history['val_accuracy'])\n",
        "    val_accuracies.append(val_acc)\n",
        "    print(f\"Fold {fold+1} - Best Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# 10. Rata-rata akurasi dari semua fold\n",
        "print(f\"\\nAverage Validation Accuracy: {np.mean(val_accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzIhlHBLttCP",
        "outputId": "f62f3f80-b3db-4218-d08e-83b9c7b8cab8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m294/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4567 - loss: 1.2860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4592 - loss: 1.2815 - val_accuracy: 0.2408 - val_loss: 1.3257 - learning_rate: 5.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7591 - loss: 0.7600"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7591 - loss: 0.7599 - val_accuracy: 0.8125 - val_loss: 0.6730 - learning_rate: 5.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m299/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.6294"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8252 - loss: 0.6292 - val_accuracy: 0.8575 - val_loss: 0.5793 - learning_rate: 5.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m296/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8584 - loss: 0.5410"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8584 - loss: 0.5411 - val_accuracy: 0.8579 - val_loss: 0.5670 - learning_rate: 5.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m298/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8727 - loss: 0.5123"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8727 - loss: 0.5123 - val_accuracy: 0.8642 - val_loss: 0.5614 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8907 - loss: 0.4594 - val_accuracy: 0.8642 - val_loss: 0.5588 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9016 - loss: 0.4249 - val_accuracy: 0.8629 - val_loss: 0.5605 - learning_rate: 5.0000e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9098 - loss: 0.4041 - val_accuracy: 0.8608 - val_loss: 0.5667 - learning_rate: 5.0000e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9134 - loss: 0.3904 - val_accuracy: 0.8512 - val_loss: 0.5882 - learning_rate: 5.0000e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.3664 - val_accuracy: 0.8567 - val_loss: 0.5926 - learning_rate: 5.0000e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9285 - loss: 0.3553 - val_accuracy: 0.8583 - val_loss: 0.5882 - learning_rate: 2.5000e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9310 - loss: 0.3384 - val_accuracy: 0.8562 - val_loss: 0.5918 - learning_rate: 2.5000e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.3305 - val_accuracy: 0.8546 - val_loss: 0.6000 - learning_rate: 2.5000e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.3093 - val_accuracy: 0.8542 - val_loss: 0.6021 - learning_rate: 2.5000e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9419 - loss: 0.3014 - val_accuracy: 0.8521 - val_loss: 0.6235 - learning_rate: 2.5000e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9451 - loss: 0.2994 - val_accuracy: 0.8533 - val_loss: 0.6227 - learning_rate: 1.2500e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9512 - loss: 0.2775 - val_accuracy: 0.8562 - val_loss: 0.6279 - learning_rate: 1.2500e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.2841 - val_accuracy: 0.8571 - val_loss: 0.6224 - learning_rate: 1.2500e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9507 - loss: 0.2729 - val_accuracy: 0.8558 - val_loss: 0.6331 - learning_rate: 1.2500e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9532 - loss: 0.2610 - val_accuracy: 0.8542 - val_loss: 0.6437 - learning_rate: 1.2500e-04\n",
            "Fold 1 - Best Val Accuracy: 0.8642\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/150\n",
            "\u001b[1m294/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5099 - loss: 1.2043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5120 - loss: 1.2006 - val_accuracy: 0.2529 - val_loss: 1.2993 - learning_rate: 5.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m296/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7664 - loss: 0.7568"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7666 - loss: 0.7564 - val_accuracy: 0.8179 - val_loss: 0.6825 - learning_rate: 5.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m291/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 0.5973"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 0.5974 - val_accuracy: 0.8396 - val_loss: 0.5972 - learning_rate: 5.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8632 - loss: 0.5405 - val_accuracy: 0.8392 - val_loss: 0.5824 - learning_rate: 5.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8741 - loss: 0.4929 - val_accuracy: 0.8392 - val_loss: 0.5832 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8945 - loss: 0.4542"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8945 - loss: 0.4542 - val_accuracy: 0.8479 - val_loss: 0.5774 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9058 - loss: 0.4104 - val_accuracy: 0.8458 - val_loss: 0.5885 - learning_rate: 5.0000e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.4140 - val_accuracy: 0.8383 - val_loss: 0.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9178 - loss: 0.3788 - val_accuracy: 0.8396 - val_loss: 0.6039 - learning_rate: 5.0000e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9211 - loss: 0.3639 - val_accuracy: 0.8388 - val_loss: 0.6192 - learning_rate: 5.0000e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9331 - loss: 0.3400 - val_accuracy: 0.8417 - val_loss: 0.6141 - learning_rate: 5.0000e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.3426 - val_accuracy: 0.8425 - val_loss: 0.6244 - learning_rate: 2.5000e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9336 - loss: 0.3268 - val_accuracy: 0.8462 - val_loss: 0.6240 - learning_rate: 2.5000e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9460 - loss: 0.3076 - val_accuracy: 0.8429 - val_loss: 0.6442 - learning_rate: 2.5000e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9498 - loss: 0.2852 - val_accuracy: 0.8388 - val_loss: 0.6588 - learning_rate: 2.5000e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9482 - loss: 0.2851 - val_accuracy: 0.8379 - val_loss: 0.6762 - learning_rate: 2.5000e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9484 - loss: 0.2800 - val_accuracy: 0.8371 - val_loss: 0.6676 - learning_rate: 1.2500e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9557 - loss: 0.2608 - val_accuracy: 0.8413 - val_loss: 0.6725 - learning_rate: 1.2500e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9540 - loss: 0.2693 - val_accuracy: 0.8433 - val_loss: 0.6855 - learning_rate: 1.2500e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9551 - loss: 0.2597 - val_accuracy: 0.8400 - val_loss: 0.6926 - learning_rate: 1.2500e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9556 - loss: 0.2590 - val_accuracy: 0.8413 - val_loss: 0.6888 - learning_rate: 1.2500e-04\n",
            "Fold 2 - Best Val Accuracy: 0.8479\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/150\n",
            "\u001b[1m292/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5065 - loss: 1.2186"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5092 - loss: 1.2136 - val_accuracy: 0.4652 - val_loss: 1.1076 - learning_rate: 5.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m297/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.7511"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7567 - loss: 0.7508 - val_accuracy: 0.8158 - val_loss: 0.6596 - learning_rate: 5.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m299/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8330 - loss: 0.6079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8330 - loss: 0.6079 - val_accuracy: 0.8358 - val_loss: 0.5955 - learning_rate: 5.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m299/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 0.5501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8565 - loss: 0.5501 - val_accuracy: 0.8441 - val_loss: 0.5857 - learning_rate: 5.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8840 - loss: 0.4879 - val_accuracy: 0.8420 - val_loss: 0.5860 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m291/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8868 - loss: 0.4692"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8868 - loss: 0.4692 - val_accuracy: 0.8483 - val_loss: 0.5921 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m294/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.4253"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9046 - loss: 0.4256 - val_accuracy: 0.8512 - val_loss: 0.5897 - learning_rate: 5.0000e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9104 - loss: 0.4014 - val_accuracy: 0.8470 - val_loss: 0.5931 - learning_rate: 5.0000e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m292/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9227 - loss: 0.3759"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9226 - loss: 0.3761 - val_accuracy: 0.8529 - val_loss: 0.5999 - learning_rate: 5.0000e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9109 - loss: 0.3962 - val_accuracy: 0.8495 - val_loss: 0.6219 - learning_rate: 5.0000e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9221 - loss: 0.3619 - val_accuracy: 0.8433 - val_loss: 0.6373 - learning_rate: 5.0000e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9243 - loss: 0.3484 - val_accuracy: 0.8474 - val_loss: 0.6415 - learning_rate: 5.0000e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9328 - loss: 0.3258 - val_accuracy: 0.8399 - val_loss: 0.6646 - learning_rate: 5.0000e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9385 - loss: 0.3175 - val_accuracy: 0.8470 - val_loss: 0.6772 - learning_rate: 5.0000e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.2974 - val_accuracy: 0.8424 - val_loss: 0.6741 - learning_rate: 2.5000e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.2816 - val_accuracy: 0.8420 - val_loss: 0.6761 - learning_rate: 2.5000e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9464 - loss: 0.2836 - val_accuracy: 0.8383 - val_loss: 0.6991 - learning_rate: 2.5000e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9519 - loss: 0.2646 - val_accuracy: 0.8374 - val_loss: 0.6954 - learning_rate: 2.5000e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9559 - loss: 0.2538 - val_accuracy: 0.8391 - val_loss: 0.7095 - learning_rate: 2.5000e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.2525 - val_accuracy: 0.8391 - val_loss: 0.7075 - learning_rate: 1.2500e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9593 - loss: 0.2464 - val_accuracy: 0.8420 - val_loss: 0.7175 - learning_rate: 1.2500e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.2482 - val_accuracy: 0.8395 - val_loss: 0.7186 - learning_rate: 1.2500e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9552 - loss: 0.2548 - val_accuracy: 0.8349 - val_loss: 0.7265 - learning_rate: 1.2500e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.2434 - val_accuracy: 0.8370 - val_loss: 0.7233 - learning_rate: 1.2500e-04\n",
            "Fold 3 - Best Val Accuracy: 0.8529\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/150\n",
            "\u001b[1m295/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4631 - loss: 1.3351"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4654 - loss: 1.3306 - val_accuracy: 0.3831 - val_loss: 1.1529 - learning_rate: 5.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m296/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7633 - loss: 0.7590"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7635 - loss: 0.7586 - val_accuracy: 0.8295 - val_loss: 0.6501 - learning_rate: 5.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m292/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8313 - loss: 0.6112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8313 - loss: 0.6112 - val_accuracy: 0.8416 - val_loss: 0.5904 - learning_rate: 5.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m296/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8614 - loss: 0.5452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8613 - loss: 0.5454 - val_accuracy: 0.8433 - val_loss: 0.5878 - learning_rate: 5.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m294/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8775 - loss: 0.5009"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8774 - loss: 0.5011 - val_accuracy: 0.8529 - val_loss: 0.5750 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m296/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8967 - loss: 0.4504"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8966 - loss: 0.4507 - val_accuracy: 0.8554 - val_loss: 0.5717 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9004 - loss: 0.4340 - val_accuracy: 0.8554 - val_loss: 0.5710 - learning_rate: 5.0000e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9096 - loss: 0.4037 - val_accuracy: 0.8499 - val_loss: 0.5875 - learning_rate: 5.0000e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9164 - loss: 0.3869 - val_accuracy: 0.8541 - val_loss: 0.5973 - learning_rate: 5.0000e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9181 - loss: 0.3814 - val_accuracy: 0.8524 - val_loss: 0.5974 - learning_rate: 5.0000e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.3620 - val_accuracy: 0.8533 - val_loss: 0.6070 - learning_rate: 5.0000e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m296/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9342 - loss: 0.3368"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9341 - loss: 0.3369 - val_accuracy: 0.8587 - val_loss: 0.6073 - learning_rate: 2.5000e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m294/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9358 - loss: 0.3278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.3277 - val_accuracy: 0.8604 - val_loss: 0.6125 - learning_rate: 2.5000e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9420 - loss: 0.2990 - val_accuracy: 0.8587 - val_loss: 0.6358 - learning_rate: 2.5000e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.2856 - val_accuracy: 0.8541 - val_loss: 0.6484 - learning_rate: 2.5000e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9400 - loss: 0.2977 - val_accuracy: 0.8520 - val_loss: 0.6622 - learning_rate: 2.5000e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9470 - loss: 0.2828 - val_accuracy: 0.8499 - val_loss: 0.6658 - learning_rate: 2.5000e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9470 - loss: 0.2897 - val_accuracy: 0.8508 - val_loss: 0.6774 - learning_rate: 2.5000e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.2808 - val_accuracy: 0.8512 - val_loss: 0.6718 - learning_rate: 1.2500e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9514 - loss: 0.2738 - val_accuracy: 0.8524 - val_loss: 0.6654 - learning_rate: 1.2500e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.2665 - val_accuracy: 0.8541 - val_loss: 0.6699 - learning_rate: 1.2500e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9601 - loss: 0.2475 - val_accuracy: 0.8554 - val_loss: 0.6753 - learning_rate: 1.2500e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9605 - loss: 0.2428 - val_accuracy: 0.8537 - val_loss: 0.6800 - learning_rate: 1.2500e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9557 - loss: 0.2507 - val_accuracy: 0.8566 - val_loss: 0.6829 - learning_rate: 6.2500e-05\n",
            "Epoch 25/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9591 - loss: 0.2502 - val_accuracy: 0.8549 - val_loss: 0.6808 - learning_rate: 6.2500e-05\n",
            "Epoch 26/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9585 - loss: 0.2395 - val_accuracy: 0.8541 - val_loss: 0.6842 - learning_rate: 6.2500e-05\n",
            "Epoch 27/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.2447 - val_accuracy: 0.8562 - val_loss: 0.6851 - learning_rate: 6.2500e-05\n",
            "Epoch 28/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9602 - loss: 0.2359 - val_accuracy: 0.8537 - val_loss: 0.6925 - learning_rate: 6.2500e-05\n",
            "Fold 4 - Best Val Accuracy: 0.8604\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/150\n",
            "\u001b[1m296/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4980 - loss: 1.2793"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4995 - loss: 1.2762 - val_accuracy: 0.3110 - val_loss: 1.2028 - learning_rate: 5.0000e-04\n",
            "Epoch 2/150\n",
            "\u001b[1m293/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7539 - loss: 0.7732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7542 - loss: 0.7724 - val_accuracy: 0.8020 - val_loss: 0.6910 - learning_rate: 5.0000e-04\n",
            "Epoch 3/150\n",
            "\u001b[1m297/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8301 - loss: 0.6126"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8301 - loss: 0.6126 - val_accuracy: 0.8399 - val_loss: 0.6102 - learning_rate: 5.0000e-04\n",
            "Epoch 4/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8617 - loss: 0.5464 - val_accuracy: 0.8395 - val_loss: 0.5970 - learning_rate: 5.0000e-04\n",
            "Epoch 5/150\n",
            "\u001b[1m297/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8799 - loss: 0.5037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8799 - loss: 0.5037 - val_accuracy: 0.8429 - val_loss: 0.5971 - learning_rate: 5.0000e-04\n",
            "Epoch 6/150\n",
            "\u001b[1m296/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8971 - loss: 0.4546"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8969 - loss: 0.4549 - val_accuracy: 0.8454 - val_loss: 0.6012 - learning_rate: 5.0000e-04\n",
            "Epoch 7/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9002 - loss: 0.4440 - val_accuracy: 0.8408 - val_loss: 0.6021 - learning_rate: 5.0000e-04\n",
            "Epoch 8/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9066 - loss: 0.4106 - val_accuracy: 0.8429 - val_loss: 0.6092 - learning_rate: 5.0000e-04\n",
            "Epoch 9/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9187 - loss: 0.3809 - val_accuracy: 0.8404 - val_loss: 0.6122 - learning_rate: 5.0000e-04\n",
            "Epoch 10/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9211 - loss: 0.3709 - val_accuracy: 0.8378 - val_loss: 0.6386 - learning_rate: 5.0000e-04\n",
            "Epoch 11/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9244 - loss: 0.3555 - val_accuracy: 0.8378 - val_loss: 0.6363 - learning_rate: 5.0000e-04\n",
            "Epoch 12/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9366 - loss: 0.3217 - val_accuracy: 0.8404 - val_loss: 0.6418 - learning_rate: 2.5000e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9414 - loss: 0.3114 - val_accuracy: 0.8429 - val_loss: 0.6484 - learning_rate: 2.5000e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9415 - loss: 0.3111 - val_accuracy: 0.8387 - val_loss: 0.6612 - learning_rate: 2.5000e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9454 - loss: 0.2886 - val_accuracy: 0.8454 - val_loss: 0.6650 - learning_rate: 2.5000e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9444 - loss: 0.2988 - val_accuracy: 0.8337 - val_loss: 0.6784 - learning_rate: 2.5000e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.2826 - val_accuracy: 0.8378 - val_loss: 0.6829 - learning_rate: 1.2500e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9508 - loss: 0.2678 - val_accuracy: 0.8362 - val_loss: 0.6881 - learning_rate: 1.2500e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.2681 - val_accuracy: 0.8320 - val_loss: 0.6919 - learning_rate: 1.2500e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9509 - loss: 0.2739 - val_accuracy: 0.8366 - val_loss: 0.7001 - learning_rate: 1.2500e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9565 - loss: 0.2597 - val_accuracy: 0.8412 - val_loss: 0.7115 - learning_rate: 1.2500e-04\n",
            "Fold 5 - Best Val Accuracy: 0.8454\n",
            "\n",
            "Average Validation Accuracy: 0.8541\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}